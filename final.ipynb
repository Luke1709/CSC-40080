{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Iterative Imputer & Random Forest\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('city_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>18.22</td>\n",
       "      <td>17.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.64</td>\n",
       "      <td>133.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>15.69</td>\n",
       "      <td>16.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>24.55</td>\n",
       "      <td>34.06</td>\n",
       "      <td>3.68</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.40</td>\n",
       "      <td>19.30</td>\n",
       "      <td>29.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.40</td>\n",
       "      <td>29.07</td>\n",
       "      <td>30.70</td>\n",
       "      <td>6.80</td>\n",
       "      <td>16.40</td>\n",
       "      <td>2.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>18.48</td>\n",
       "      <td>17.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>18.59</td>\n",
       "      <td>36.08</td>\n",
       "      <td>4.43</td>\n",
       "      <td>10.14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.42</td>\n",
       "      <td>37.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.10</td>\n",
       "      <td>39.33</td>\n",
       "      <td>39.31</td>\n",
       "      <td>7.01</td>\n",
       "      <td>18.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City        Date  PM2.5  PM10     NO    NO2    NOx  NH3     CO    SO2  \\\n",
       "0  Ahmedabad  2015-01-01    NaN   NaN   0.92  18.22  17.15  NaN   0.92  27.64   \n",
       "1  Ahmedabad  2015-01-02    NaN   NaN   0.97  15.69  16.46  NaN   0.97  24.55   \n",
       "2  Ahmedabad  2015-01-03    NaN   NaN  17.40  19.30  29.70  NaN  17.40  29.07   \n",
       "3  Ahmedabad  2015-01-04    NaN   NaN   1.70  18.48  17.97  NaN   1.70  18.59   \n",
       "4  Ahmedabad  2015-01-05    NaN   NaN  22.10  21.42  37.76  NaN  22.10  39.33   \n",
       "\n",
       "       O3  Benzene  Toluene  Xylene  AQI AQI_Bucket  \n",
       "0  133.36     0.00     0.02    0.00  NaN        NaN  \n",
       "1   34.06     3.68     5.50    3.77  NaN        NaN  \n",
       "2   30.70     6.80    16.40    2.25  NaN        NaN  \n",
       "3   36.08     4.43    10.14    1.00  NaN        NaN  \n",
       "4   39.31     7.01    18.89    2.78  NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop AQI_Bucket, not needed for this task\n",
    "- Drop any rows missing AQI values from simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset from raw data, dropping AQI Bucket\n",
    "data = raw_data.drop(['AQI_Bucket'], axis=1)\n",
    "\n",
    "# Dropping rows with missing AQI values\n",
    "data = data.dropna(subset=['AQI'])\n",
    "\n",
    "# Convert the date to correct format\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reduce the data to 3 cities to reduce geographical variation: Jaipur, Amritsar, Thiruvananthapuram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['Amritsar', 'Amaravati', 'Jaipur']\n",
    "data = data[data['City'].isin(regions)]\n",
    "\n",
    "# Reset Index\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3061</td>\n",
       "      <td>2971.000</td>\n",
       "      <td>3031.000</td>\n",
       "      <td>3006.000</td>\n",
       "      <td>3049.000</td>\n",
       "      <td>2727.000</td>\n",
       "      <td>3045.000</td>\n",
       "      <td>2979.000</td>\n",
       "      <td>2921.000</td>\n",
       "      <td>2976.000</td>\n",
       "      <td>2872.000</td>\n",
       "      <td>2855.000</td>\n",
       "      <td>1617.000</td>\n",
       "      <td>3061.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019-01-04 22:02:23.482522112</td>\n",
       "      <td>50.159</td>\n",
       "      <td>107.412</td>\n",
       "      <td>13.281</td>\n",
       "      <td>24.375</td>\n",
       "      <td>30.779</td>\n",
       "      <td>17.991</td>\n",
       "      <td>0.665</td>\n",
       "      <td>11.003</td>\n",
       "      <td>35.744</td>\n",
       "      <td>2.194</td>\n",
       "      <td>4.145</td>\n",
       "      <td>4.885</td>\n",
       "      <td>118.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2017-02-28 00:00:00</td>\n",
       "      <td>2.850</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2018-04-13 00:00:00</td>\n",
       "      <td>28.375</td>\n",
       "      <td>62.905</td>\n",
       "      <td>4.880</td>\n",
       "      <td>11.640</td>\n",
       "      <td>15.945</td>\n",
       "      <td>9.720</td>\n",
       "      <td>0.440</td>\n",
       "      <td>7.210</td>\n",
       "      <td>21.210</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.150</td>\n",
       "      <td>74.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019-01-16 00:00:00</td>\n",
       "      <td>43.630</td>\n",
       "      <td>97.700</td>\n",
       "      <td>10.400</td>\n",
       "      <td>18.960</td>\n",
       "      <td>26.780</td>\n",
       "      <td>14.270</td>\n",
       "      <td>0.660</td>\n",
       "      <td>10.250</td>\n",
       "      <td>31.420</td>\n",
       "      <td>1.130</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.000</td>\n",
       "      <td>104.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019-10-17 00:00:00</td>\n",
       "      <td>63.585</td>\n",
       "      <td>138.735</td>\n",
       "      <td>16.555</td>\n",
       "      <td>32.030</td>\n",
       "      <td>39.130</td>\n",
       "      <td>23.070</td>\n",
       "      <td>0.860</td>\n",
       "      <td>13.250</td>\n",
       "      <td>46.240</td>\n",
       "      <td>2.850</td>\n",
       "      <td>5.515</td>\n",
       "      <td>8.130</td>\n",
       "      <td>143.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020-07-01 00:00:00</td>\n",
       "      <td>868.660</td>\n",
       "      <td>917.080</td>\n",
       "      <td>103.440</td>\n",
       "      <td>237.270</td>\n",
       "      <td>150.960</td>\n",
       "      <td>129.460</td>\n",
       "      <td>3.830</td>\n",
       "      <td>67.260</td>\n",
       "      <td>172.280</td>\n",
       "      <td>53.890</td>\n",
       "      <td>76.320</td>\n",
       "      <td>137.450</td>\n",
       "      <td>869.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35.894</td>\n",
       "      <td>62.526</td>\n",
       "      <td>12.981</td>\n",
       "      <td>17.878</td>\n",
       "      <td>22.030</td>\n",
       "      <td>12.889</td>\n",
       "      <td>0.440</td>\n",
       "      <td>5.941</td>\n",
       "      <td>20.465</td>\n",
       "      <td>3.328</td>\n",
       "      <td>5.079</td>\n",
       "      <td>8.077</td>\n",
       "      <td>65.766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date     PM2.5      PM10        NO       NO2  \\\n",
       "count                           3061  2971.000  3031.000  3006.000  3049.000   \n",
       "mean   2019-01-04 22:02:23.482522112    50.159   107.412    13.281    24.375   \n",
       "min              2017-02-28 00:00:00     2.850     0.420     0.250     0.010   \n",
       "25%              2018-04-13 00:00:00    28.375    62.905     4.880    11.640   \n",
       "50%              2019-01-16 00:00:00    43.630    97.700    10.400    18.960   \n",
       "75%              2019-10-17 00:00:00    63.585   138.735    16.555    32.030   \n",
       "max              2020-07-01 00:00:00   868.660   917.080   103.440   237.270   \n",
       "std                              NaN    35.894    62.526    12.981    17.878   \n",
       "\n",
       "            NOx       NH3        CO       SO2        O3   Benzene   Toluene  \\\n",
       "count  2727.000  3045.000  2979.000  2921.000  2976.000  2872.000  2855.000   \n",
       "mean     30.779    17.991     0.665    11.003    35.744     2.194     4.145   \n",
       "min       0.860     0.060     0.000     0.710     0.240     0.000     0.000   \n",
       "25%      15.945     9.720     0.440     7.210    21.210     0.280     1.100   \n",
       "50%      26.780    14.270     0.660    10.250    31.420     1.130     2.240   \n",
       "75%      39.130    23.070     0.860    13.250    46.240     2.850     5.515   \n",
       "max     150.960   129.460     3.830    67.260   172.280    53.890    76.320   \n",
       "std      22.030    12.889     0.440     5.941    20.465     3.328     5.079   \n",
       "\n",
       "         Xylene       AQI  \n",
       "count  1617.000  3061.000  \n",
       "mean      4.885   118.074  \n",
       "min       0.000    20.000  \n",
       "25%       0.150    74.000  \n",
       "50%       2.000   104.000  \n",
       "75%       8.130   143.000  \n",
       "max     137.450   869.000  \n",
       "std       8.077    65.766  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data summaries \n",
    "np.round(data.describe(),3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*EDA on how pollutants vary with AQI*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City          0\n",
       "Date          0\n",
       "PM2.5        90\n",
       "PM10         30\n",
       "NO           55\n",
       "NO2          12\n",
       "NOx         334\n",
       "NH3          16\n",
       "CO           82\n",
       "SO2         140\n",
       "O3           85\n",
       "Benzene     189\n",
       "Toluene     206\n",
       "Xylene     1444\n",
       "AQI           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop Benzene, Toluene, Xylene as these do not directly correlate with AQI and have significant numbers of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Benzene, Toluene, Xylene from data\n",
    "data.drop(['Benzene', 'Toluene', 'Xylene'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Heatmaps to show distribution of missing data*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Add missing Values using Iterative Imputer package*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM2.5    0\n",
      "PM10     0\n",
      "NO       0\n",
      "NO2      0\n",
      "NOx      0\n",
      "NH3      0\n",
      "CO       0\n",
      "SO2      0\n",
      "O3       0\n",
      "AQI      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'City' and 'Date' column, as it's not used for imputation\n",
    "data_model = data.drop(['City', 'Date'], axis=1)\n",
    "\n",
    "# Initialize the Iterative Imputer with a RandomForestRegressor\n",
    "imputer = IterativeImputer(estimator=RandomForestRegressor(), max_iter=10, random_state=42)\n",
    "\n",
    "# Apply the imputer to the dataset\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(data_model), columns=data_model.columns)\n",
    "\n",
    "# Display information about missing values after imputation\n",
    "print(df_imputed.isnull().sum())\n",
    "\n",
    "# Merge the imputed dataframe and the dataset\n",
    "data_new = pd.concat([data[['City', 'Date']], df_imputed], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datasets\n",
    "amarvati = pd.read_csv('amarvati.csv')\n",
    "amritsar = pd.read_csv('amritsar.csv')\n",
    "jaipur = pd.read_csv('jaipur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' columns to datetime and remove timezones for consistency\n",
    "data_new['Date'] = pd.to_datetime(data_new['Date']).dt.tz_localize(None)\n",
    "amarvati['date'] = pd.to_datetime(amarvati['date']).dt.tz_localize(None)\n",
    "jaipur['date'] = pd.to_datetime(jaipur['date']).dt.tz_localize(None)\n",
    "amritsar['date'] = pd.to_datetime(amritsar['date']).dt.tz_localize(None)\n",
    "\n",
    "# Rename the 'date' columns to 'Date' for consistency\n",
    "amarvati.rename(columns={'date': 'Date'}, inplace=True)\n",
    "jaipur.rename(columns={'date': 'Date'}, inplace=True)\n",
    "amritsar.rename(columns={'date': 'Date'}, inplace=True)\n",
    "\n",
    "# Add the 'City' column to each weather dataset\n",
    "amarvati['City'] = 'Amaravati'\n",
    "jaipur['City'] = 'Jaipur'\n",
    "amritsar['City'] = 'Amritsar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity_max</th>\n",
       "      <th>dew_point_mean</th>\n",
       "      <th>dew_point_max</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>cloud_cover_sum</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_speed_100m_mean</th>\n",
       "      <th>wind_speed_100m_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>81.40</td>\n",
       "      <td>124.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.50</td>\n",
       "      <td>12.08</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>...</td>\n",
       "      <td>89.346016</td>\n",
       "      <td>19.013000</td>\n",
       "      <td>21.263000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>819.000009</td>\n",
       "      <td>9.180352</td>\n",
       "      <td>16.808570</td>\n",
       "      <td>15.935398</td>\n",
       "      <td>27.248455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>78.32</td>\n",
       "      <td>129.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.96</td>\n",
       "      <td>...</td>\n",
       "      <td>95.198590</td>\n",
       "      <td>18.248417</td>\n",
       "      <td>21.063000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.800023</td>\n",
       "      <td>7.759277</td>\n",
       "      <td>11.988594</td>\n",
       "      <td>14.097954</td>\n",
       "      <td>22.183128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>88.76</td>\n",
       "      <td>135.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>30.85</td>\n",
       "      <td>21.77</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>97.275760</td>\n",
       "      <td>18.960917</td>\n",
       "      <td>21.463001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.900014</td>\n",
       "      <td>6.287076</td>\n",
       "      <td>9.085988</td>\n",
       "      <td>11.361810</td>\n",
       "      <td>17.418196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>64.18</td>\n",
       "      <td>104.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.07</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.00</td>\n",
       "      <td>...</td>\n",
       "      <td>94.871315</td>\n",
       "      <td>17.425500</td>\n",
       "      <td>21.013000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.000013</td>\n",
       "      <td>7.019016</td>\n",
       "      <td>13.684735</td>\n",
       "      <td>13.233190</td>\n",
       "      <td>25.630886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>72.47</td>\n",
       "      <td>114.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>23.20</td>\n",
       "      <td>16.59</td>\n",
       "      <td>12.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10.55</td>\n",
       "      <td>...</td>\n",
       "      <td>96.376900</td>\n",
       "      <td>17.617167</td>\n",
       "      <td>20.663000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.000007</td>\n",
       "      <td>10.355873</td>\n",
       "      <td>14.186923</td>\n",
       "      <td>18.022025</td>\n",
       "      <td>23.904108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        City       Date  PM2.5    PM10    NO    NO2    NOx    NH3    CO  \\\n",
       "0  Amaravati 2017-11-25  81.40  124.50  1.44  20.50  12.08  10.72  0.12   \n",
       "1  Amaravati 2017-11-26  78.32  129.06  1.26  26.00  14.85  10.28  0.14   \n",
       "2  Amaravati 2017-11-27  88.76  135.32  6.60  30.85  21.77  12.91  0.11   \n",
       "3  Amaravati 2017-11-28  64.18  104.09  2.56  28.07  17.01  11.42  0.09   \n",
       "4  Amaravati 2017-11-29  72.47  114.84  5.23  23.20  16.59  12.25  0.16   \n",
       "\n",
       "     SO2  ...  humidity_max  dew_point_mean  dew_point_max  precipitation_sum  \\\n",
       "0  15.24  ...     89.346016       19.013000      21.263000                0.0   \n",
       "1  26.96  ...     95.198590       18.248417      21.063000                0.0   \n",
       "2  33.59  ...     97.275760       18.960917      21.463001                0.0   \n",
       "3  19.00  ...     94.871315       17.425500      21.013000                0.0   \n",
       "4  10.55  ...     96.376900       17.617167      20.663000                0.0   \n",
       "\n",
       "   rain_sum  cloud_cover_sum  wind_speed_10m_mean  wind_speed_10m_max  \\\n",
       "0       0.0       819.000009             9.180352           16.808570   \n",
       "1       0.0       532.800023             7.759277           11.988594   \n",
       "2       0.0       618.900014             6.287076            9.085988   \n",
       "3       0.0       378.000013             7.019016           13.684735   \n",
       "4       0.0       189.000007            10.355873           14.186923   \n",
       "\n",
       "   wind_speed_100m_mean  wind_speed_100m_max  \n",
       "0             15.935398            27.248455  \n",
       "1             14.097954            22.183128  \n",
       "2             11.361810            17.418196  \n",
       "3             13.233190            25.630886  \n",
       "4             18.022025            23.904108  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map cities to the correct city csv file\n",
    "city_data = {\n",
    "    'Amaravati': amarvati,\n",
    "    'Jaipur': jaipur,\n",
    "    'Amritsar': amritsar\n",
    "}\n",
    "\n",
    "# Initialise empty lists for storing new data\n",
    "temperature_mean = []\n",
    "temperature_max = []\n",
    "humidity_mean = []\n",
    "humidity_max = []\n",
    "dew_point_mean = []\n",
    "dew_point_max = []\n",
    "precipitation_sum = []\n",
    "rain_sum = []\n",
    "cloud_cover_sum = []\n",
    "wind_speed_10m_mean = []\n",
    "wind_speed_10m_max = []\n",
    "wind_speed_100m_mean = []\n",
    "wind_speed_100m_max = []\n",
    "\n",
    "# Loop over each row in data_new_df\n",
    "for index, row in data_new.iterrows():\n",
    "    city = row['City']\n",
    "    date = row['Date']\n",
    "    \n",
    "    # Check if the city has corresponding weather data\n",
    "    if city in city_data:\n",
    "        weather_df = city_data[city]\n",
    "        # Find the matching row in the city's weather DataFrame\n",
    "        match = weather_df[weather_df['Date'] == date]\n",
    "        \n",
    "        if not match.empty:\n",
    "            # Append values to the lists if a match is found\n",
    "            temperature_mean.append(match['temperature_mean'].values[0])\n",
    "            temperature_max.append(match['temperature_max'].values[0])\n",
    "            humidity_mean.append(match['humidity_mean'].values[0])\n",
    "            humidity_max.append(match['humidity_max'].values[0])\n",
    "            dew_point_mean.append(match['dew_point_mean'].values[0])\n",
    "            dew_point_max.append(match['dew_point_max'].values[0])\n",
    "            precipitation_sum.append(match['precipitation_sum'].values[0])\n",
    "            rain_sum.append(match['rain_sum'].values[0])\n",
    "            cloud_cover_sum.append(match['cloud_cover_sum'].values[0])\n",
    "            wind_speed_10m_mean.append(match['wind_speed_10m_mean'].values[0])\n",
    "            wind_speed_10m_max.append(match['wind_speed_10m_max'].values[0])\n",
    "            wind_speed_100m_mean.append(match['wind_speed_100m_mean'].values[0])\n",
    "            wind_speed_100m_max.append(match['wind_speed_100m_max'].values[0])\n",
    "        else:\n",
    "            # Append NaN if no match is found\n",
    "            temperature_mean.append(float('nan'))\n",
    "            temperature_max.append(float('nan'))\n",
    "            humidity_mean.append(float('nan'))\n",
    "            humidity_max.append(float('nan'))\n",
    "            dew_point_mean.append(float('nan'))\n",
    "            dew_point_max.append(float('nan'))\n",
    "            precipitation_sum.append(float('nan'))\n",
    "            rain_sum.append(float('nan'))\n",
    "            cloud_cover_sum.append(float('nan'))\n",
    "            wind_speed_10m_mean.append(float('nan'))\n",
    "            wind_speed_10m_max.append(float('nan'))\n",
    "            wind_speed_100m_mean.append(float('nan'))\n",
    "            wind_speed_100m_max.append(float('nan'))\n",
    "    else:\n",
    "        # Append NaN if no matching city is found\n",
    "        temperature_mean.append(float('nan'))\n",
    "        temperature_max.append(float('nan'))\n",
    "        humidity_mean.append(float('nan'))\n",
    "        humidity_max.append(float('nan'))\n",
    "        dew_point_mean.append(float('nan'))\n",
    "        dew_point_max.append(float('nan'))\n",
    "        precipitation_sum.append(float('nan'))\n",
    "        rain_sum.append(float('nan'))\n",
    "        cloud_cover_sum.append(float('nan'))\n",
    "        wind_speed_10m_mean.append(float('nan'))\n",
    "        wind_speed_10m_max.append(float('nan'))\n",
    "        wind_speed_100m_mean.append(float('nan'))\n",
    "        wind_speed_100m_max.append(float('nan'))\n",
    "\n",
    "# Add the new data to the DataFrame\n",
    "data_new['temperature_mean'] = temperature_mean\n",
    "data_new['temperature_max'] = temperature_max\n",
    "data_new['humidity_mean'] = humidity_mean\n",
    "data_new['humidity_max'] = humidity_max\n",
    "data_new['dew_point_mean'] = dew_point_mean\n",
    "data_new['dew_point_max'] = dew_point_max\n",
    "data_new['precipitation_sum'] = precipitation_sum\n",
    "data_new['rain_sum'] = rain_sum\n",
    "data_new['cloud_cover_sum'] = cloud_cover_sum\n",
    "data_new['wind_speed_10m_mean'] = wind_speed_10m_mean\n",
    "data_new['wind_speed_10m_max'] = wind_speed_10m_max\n",
    "data_new['wind_speed_100m_mean'] = wind_speed_100m_mean\n",
    "data_new['wind_speed_100m_max'] = wind_speed_100m_max\n",
    "\n",
    "data_new.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Ridge & Lasso Regression to examine features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = data_new[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'temperature_mean', 'temperature_max', 'humidity_mean', 'humidity_max', 'dew_point_mean', 'dew_point_max', 'precipitation_sum', 'rain_sum', 'cloud_cover_sum', 'wind_speed_10m_mean', 'wind_speed_10m_max', 'wind_speed_100m_mean', 'wind_speed_100m_max']]\n",
    "y = data_new['AQI'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 627.0643751626552\n",
      "R-squared: 0.8336402663097588\n",
      "[55.8271  3.4606  4.6987 -1.4274 -2.5382  4.5062 -1.332   7.1504 -5.611\n",
      "  0.7558 -1.5483  1.3308  8.5084 -3.1861  0.0545  0.0545 -0.85    2.6151\n",
      " -1.5857 -0.9619  2.395 ]\n",
      "Cross-validated MSE (for each fold): [ 667.95865495 1819.8012489  1189.64304189  702.39796419  526.37211722]\n",
      "Average MSE: 981.2346054296971\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardise both sets of data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initiate Ridge Regression\n",
    "ridge = Ridge(alpha=1.0) \n",
    "\n",
    "# Fit the model\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients\n",
    "print(np.round(ridge.coef_,4))\n",
    "\n",
    "ridge_cv = cross_val_score(ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -ridge_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -ridge_cv.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha Tuning?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 624.021710041988\n",
      "R-squared: 0.8344474832068303\n",
      "[55.7718  2.6891  3.8911 -0.     -2.3823  4.3188 -1.1216  7.0827 -0.0174\n",
      " -0.4816  1.7652  1.3773  0.4976 -0.     -0.     -0.     -0.7658  1.313\n",
      " -0.1781  0.1162  1.0772]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Using majority of the same code as above:\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = lasso.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients\n",
    "print(np.round(lasso.coef_,4))\n",
    "\n",
    "lasso_cv = cross_val_score(lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -lasso_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -lasso_cv.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha Tuning?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As PM2.5 particles are included in PM10, we face the issue of multicolinearity. By applying PCA onto these features we can reduce this.\n",
    "\n",
    "This improves the Ridge and Lasso Regression models but will sacrifice interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "pm_data_scaled = scaler.fit_transform(data_new[['PM2.5', 'PM10']])\n",
    "\n",
    "# Step 2: Apply PCA to PM2.5 and PM10\n",
    "pca = PCA(n_components=2)  # Use 2 components because we have 2 features\n",
    "pm_pca = pca.fit_transform(pm_data_scaled)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "pm_pca_df = pd.DataFrame(pm_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Display the new components\n",
    "print(\"Principal Components:\")\n",
    "print(pm_pca_df)\n",
    "\n",
    "# Explained variance to understand how much information is captured by each component\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance Ratio: {explained_variance}\")\n",
    "\n",
    "# Keep PC1 and drop both PM2.5 and PM10\n",
    "X.drop(['PM2.5', 'PM10'], axis=1, inplace=True)\n",
    "\n",
    "# Add PC1\n",
    "X.insert(0, 'PC1', pm_pca[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 627.0643751626552\n",
      "R-squared: 0.8336402663097588\n",
      "[55.8271  3.4606  4.6987 -1.4274 -2.5382  4.5062 -1.332   7.1504 -5.611\n",
      "  0.7558 -1.5483  1.3308  8.5084 -3.1861  0.0545  0.0545 -0.85    2.6151\n",
      " -1.5857 -0.9619  2.395 ]\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardise both sets of data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initiate Ridge Regression\n",
    "ridge = Ridge(alpha=1.0) \n",
    "\n",
    "# Fit the model\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients\n",
    "print(np.round(ridge.coef_,4))\n",
    "\n",
    "ridge_cv = cross_val_score(ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -ridge_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -ridge_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 624.021710041988\n",
      "R-squared: 0.8344474832068303\n",
      "[55.7718  2.6891  3.8911 -0.     -2.3823  4.3188 -1.1216  7.0827 -0.0174\n",
      " -0.4816  1.7652  1.3773  0.4976 -0.     -0.     -0.     -0.7658  1.313\n",
      " -0.1781  0.1162  1.0772]\n"
     ]
    }
   ],
   "source": [
    "# Using majority of the same code as above:\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = lasso.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients\n",
    "print(np.round(lasso.coef_,4))\n",
    "\n",
    "lasso_cv = cross_val_score(lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -lasso_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -lasso_cv.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can look to remove x,y and z features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor MSE: 545.7212445350733\n",
      "Random Forest Regressor R-squared: 0.855220541134373\n",
      "Cross-validated MSE (for each fold): [ 368.79150212  867.92952206 1358.08655229  804.84082892  435.31119134]\n",
      "Average MSE: 766.9919193457122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = data_new[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'temperature_mean', 'temperature_max', 'humidity_mean', 'humidity_max', 'dew_point_mean', 'dew_point_max', 'precipitation_sum', 'rain_sum', 'cloud_cover_sum', 'wind_speed_10m_mean', 'wind_speed_10m_max', 'wind_speed_100m_mean', 'wind_speed_100m_max']]\n",
    "y = data_new['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest Regressor MSE: {mse_rf}\")\n",
    "print(f\"Random Forest Regressor R-squared: {r2_rf}\")\n",
    "\n",
    "rf_cv = cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -rf_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -rf_cv.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regressor MSE: 1623.324005186619\n",
      "Support Vector Regressor R-squared: 0.5693332935302355\n",
      "Cross-validated MSE (for each fold): [2215.34000312 4243.16929408 4006.91802428 3579.50290183 1458.34728392]\n",
      "Average MSE: 3100.6555014468067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the data (SVR requires standardized input)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit the Support Vector Regression model\n",
    "svr = SVR(kernel='rbf')  # Using RBF kernel for non-linear relationships\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svr = svr.predict(X_test_scaled)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(f\"Support Vector Regressor MSE: {mse_svr}\")\n",
    "print(f\"Support Vector Regressor R-squared: {r2_svr}\")\n",
    "\n",
    "svr_cv = cross_val_score(svr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -svr_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -svr_cv.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Neural Network + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Hybrid Model (XGBoost + Neural Network) MSE: 559.0211093394437\n",
      "Tuned Hybrid Model (XGBoost + Neural Network) R-squared: 0.8516920964409596\n",
      "Cross-validated MSE (for each fold): [ 355.45837927 1365.62864126 1301.17649184  943.36093401  388.92727787]\n",
      "Average MSE: 870.9103448484191\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Initialize XGBoost and Neural Network as base learners\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=1000, random_state=42)\n",
    "\n",
    "# Create the stacking model using Linear Regression as the meta-model\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_model), ('nn', nn_model)],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# Fit the stacked model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_stacked = stacked_model.predict(X_test)\n",
    "mse_stacked = mean_squared_error(y_test, y_pred_stacked)\n",
    "r2_stacked = r2_score(y_test, y_pred_stacked)\n",
    "\n",
    "print(f\"Tuned Hybrid Model (XGBoost + Neural Network) MSE: {mse_stacked}\")\n",
    "print(f\"Tuned Hybrid Model (XGBoost + Neural Network) R-squared: {r2_stacked}\")\n",
    "\n",
    "hybrid_cv = cross_val_score(stacked_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -hybrid_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -hybrid_cv.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 14.093363488774438\n",
      "P-value: 0.0007089109067418332\n",
      "There is a statistically significant difference between the models.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "mse_model1 = -rf_cv\n",
    "mse_model2 = -svr_cv\n",
    "mse_model3 = -hybrid_cv\n",
    "\n",
    "# Step 3: Apply ANOVA test to compare the models\n",
    "f_statistic, p_value = f_oneway(mse_model1, mse_model2, mse_model3)\n",
    "\n",
    "# Step 4: Output the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the models.\")\n",
    "else:\n",
    "    print(\"No statistically significant difference between the models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Multiple Comparison of Means - Tukey HSD, FWER=0.05           \n",
      "========================================================================\n",
      "    group1        group2     meandiff p-adj    lower      upper   reject\n",
      "------------------------------------------------------------------------\n",
      " Hybrid Model Random Forest -103.9184 0.9762 -1428.8932 1221.0563  False\n",
      " Hybrid Model           SVG 2229.7452  0.002   904.7704 3554.7199   True\n",
      "Random Forest           SVG 2333.6636 0.0014  1008.6888 3658.6383   True\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Example MSE data for three models\n",
    "# Replace with your cross-validated MSE data\n",
    "mse_data = np.concatenate([mse_model1, mse_model2, mse_model3])\n",
    "\n",
    "# Corresponding labels for the models\n",
    "model_labels = (['Random Forest'] * len(mse_model1)) + (['SVG'] * len(mse_model2)) + (['Hybrid Model'] * len(mse_model3))\n",
    "\n",
    "# Create a DataFrame to hold the MSE values and corresponding model labels\n",
    "df = pd.DataFrame({'MSE': mse_data, 'Model': model_labels})\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=df['MSE'], groups=df['Model'], alpha=0.05)\n",
    "\n",
    "# Display the test results\n",
    "print(tukey)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
