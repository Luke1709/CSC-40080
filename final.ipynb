{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Iterative Imputer & Random Forest\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('city_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>18.22</td>\n",
       "      <td>17.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.64</td>\n",
       "      <td>133.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>15.69</td>\n",
       "      <td>16.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.97</td>\n",
       "      <td>24.55</td>\n",
       "      <td>34.06</td>\n",
       "      <td>3.68</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.40</td>\n",
       "      <td>19.30</td>\n",
       "      <td>29.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.40</td>\n",
       "      <td>29.07</td>\n",
       "      <td>30.70</td>\n",
       "      <td>6.80</td>\n",
       "      <td>16.40</td>\n",
       "      <td>2.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>18.48</td>\n",
       "      <td>17.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>18.59</td>\n",
       "      <td>36.08</td>\n",
       "      <td>4.43</td>\n",
       "      <td>10.14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.10</td>\n",
       "      <td>21.42</td>\n",
       "      <td>37.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.10</td>\n",
       "      <td>39.33</td>\n",
       "      <td>39.31</td>\n",
       "      <td>7.01</td>\n",
       "      <td>18.89</td>\n",
       "      <td>2.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City        Date  PM2.5  PM10     NO    NO2    NOx  NH3     CO    SO2  \\\n",
       "0  Ahmedabad  2015-01-01    NaN   NaN   0.92  18.22  17.15  NaN   0.92  27.64   \n",
       "1  Ahmedabad  2015-01-02    NaN   NaN   0.97  15.69  16.46  NaN   0.97  24.55   \n",
       "2  Ahmedabad  2015-01-03    NaN   NaN  17.40  19.30  29.70  NaN  17.40  29.07   \n",
       "3  Ahmedabad  2015-01-04    NaN   NaN   1.70  18.48  17.97  NaN   1.70  18.59   \n",
       "4  Ahmedabad  2015-01-05    NaN   NaN  22.10  21.42  37.76  NaN  22.10  39.33   \n",
       "\n",
       "       O3  Benzene  Toluene  Xylene  AQI AQI_Bucket  \n",
       "0  133.36     0.00     0.02    0.00  NaN        NaN  \n",
       "1   34.06     3.68     5.50    3.77  NaN        NaN  \n",
       "2   30.70     6.80    16.40    2.25  NaN        NaN  \n",
       "3   36.08     4.43    10.14    1.00  NaN        NaN  \n",
       "4   39.31     7.01    18.89    2.78  NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop AQI_Bucket, not needed for this task\n",
    "- Drop any rows missing AQI values from simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataset from raw data, dropping AQI Bucket\n",
    "data = raw_data.drop(['AQI_Bucket'], axis=1)\n",
    "\n",
    "# Dropping rows with missing AQI values\n",
    "data = data.dropna(subset=['AQI'])\n",
    "\n",
    "# Convert the date to correct format\n",
    "data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reduce the data to 3 cities to reduce geographical variation: Jaipur, Amritsar, Thiruvananthapuram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['Amritsar', 'Amaravati', 'Jaipur']\n",
    "data = data[data['City'].isin(regions)]\n",
    "\n",
    "# Reset Index\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3061</td>\n",
       "      <td>2971.000</td>\n",
       "      <td>3031.000</td>\n",
       "      <td>3006.000</td>\n",
       "      <td>3049.000</td>\n",
       "      <td>2727.000</td>\n",
       "      <td>3045.000</td>\n",
       "      <td>2979.000</td>\n",
       "      <td>2921.000</td>\n",
       "      <td>2976.000</td>\n",
       "      <td>2872.000</td>\n",
       "      <td>2855.000</td>\n",
       "      <td>1617.000</td>\n",
       "      <td>3061.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2019-01-04 22:02:23.482522112</td>\n",
       "      <td>50.159</td>\n",
       "      <td>107.412</td>\n",
       "      <td>13.281</td>\n",
       "      <td>24.375</td>\n",
       "      <td>30.779</td>\n",
       "      <td>17.991</td>\n",
       "      <td>0.665</td>\n",
       "      <td>11.003</td>\n",
       "      <td>35.744</td>\n",
       "      <td>2.194</td>\n",
       "      <td>4.145</td>\n",
       "      <td>4.885</td>\n",
       "      <td>118.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2017-02-28 00:00:00</td>\n",
       "      <td>2.850</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2018-04-13 00:00:00</td>\n",
       "      <td>28.375</td>\n",
       "      <td>62.905</td>\n",
       "      <td>4.880</td>\n",
       "      <td>11.640</td>\n",
       "      <td>15.945</td>\n",
       "      <td>9.720</td>\n",
       "      <td>0.440</td>\n",
       "      <td>7.210</td>\n",
       "      <td>21.210</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.150</td>\n",
       "      <td>74.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019-01-16 00:00:00</td>\n",
       "      <td>43.630</td>\n",
       "      <td>97.700</td>\n",
       "      <td>10.400</td>\n",
       "      <td>18.960</td>\n",
       "      <td>26.780</td>\n",
       "      <td>14.270</td>\n",
       "      <td>0.660</td>\n",
       "      <td>10.250</td>\n",
       "      <td>31.420</td>\n",
       "      <td>1.130</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.000</td>\n",
       "      <td>104.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019-10-17 00:00:00</td>\n",
       "      <td>63.585</td>\n",
       "      <td>138.735</td>\n",
       "      <td>16.555</td>\n",
       "      <td>32.030</td>\n",
       "      <td>39.130</td>\n",
       "      <td>23.070</td>\n",
       "      <td>0.860</td>\n",
       "      <td>13.250</td>\n",
       "      <td>46.240</td>\n",
       "      <td>2.850</td>\n",
       "      <td>5.515</td>\n",
       "      <td>8.130</td>\n",
       "      <td>143.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020-07-01 00:00:00</td>\n",
       "      <td>868.660</td>\n",
       "      <td>917.080</td>\n",
       "      <td>103.440</td>\n",
       "      <td>237.270</td>\n",
       "      <td>150.960</td>\n",
       "      <td>129.460</td>\n",
       "      <td>3.830</td>\n",
       "      <td>67.260</td>\n",
       "      <td>172.280</td>\n",
       "      <td>53.890</td>\n",
       "      <td>76.320</td>\n",
       "      <td>137.450</td>\n",
       "      <td>869.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>35.894</td>\n",
       "      <td>62.526</td>\n",
       "      <td>12.981</td>\n",
       "      <td>17.878</td>\n",
       "      <td>22.030</td>\n",
       "      <td>12.889</td>\n",
       "      <td>0.440</td>\n",
       "      <td>5.941</td>\n",
       "      <td>20.465</td>\n",
       "      <td>3.328</td>\n",
       "      <td>5.079</td>\n",
       "      <td>8.077</td>\n",
       "      <td>65.766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date     PM2.5      PM10        NO       NO2  \\\n",
       "count                           3061  2971.000  3031.000  3006.000  3049.000   \n",
       "mean   2019-01-04 22:02:23.482522112    50.159   107.412    13.281    24.375   \n",
       "min              2017-02-28 00:00:00     2.850     0.420     0.250     0.010   \n",
       "25%              2018-04-13 00:00:00    28.375    62.905     4.880    11.640   \n",
       "50%              2019-01-16 00:00:00    43.630    97.700    10.400    18.960   \n",
       "75%              2019-10-17 00:00:00    63.585   138.735    16.555    32.030   \n",
       "max              2020-07-01 00:00:00   868.660   917.080   103.440   237.270   \n",
       "std                              NaN    35.894    62.526    12.981    17.878   \n",
       "\n",
       "            NOx       NH3        CO       SO2        O3   Benzene   Toluene  \\\n",
       "count  2727.000  3045.000  2979.000  2921.000  2976.000  2872.000  2855.000   \n",
       "mean     30.779    17.991     0.665    11.003    35.744     2.194     4.145   \n",
       "min       0.860     0.060     0.000     0.710     0.240     0.000     0.000   \n",
       "25%      15.945     9.720     0.440     7.210    21.210     0.280     1.100   \n",
       "50%      26.780    14.270     0.660    10.250    31.420     1.130     2.240   \n",
       "75%      39.130    23.070     0.860    13.250    46.240     2.850     5.515   \n",
       "max     150.960   129.460     3.830    67.260   172.280    53.890    76.320   \n",
       "std      22.030    12.889     0.440     5.941    20.465     3.328     5.079   \n",
       "\n",
       "         Xylene       AQI  \n",
       "count  1617.000  3061.000  \n",
       "mean      4.885   118.074  \n",
       "min       0.000    20.000  \n",
       "25%       0.150    74.000  \n",
       "50%       2.000   104.000  \n",
       "75%       8.130   143.000  \n",
       "max     137.450   869.000  \n",
       "std       8.077    65.766  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data summaries \n",
    "np.round(data.describe(),3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City          0\n",
       "Date          0\n",
       "PM2.5        90\n",
       "PM10         30\n",
       "NO           55\n",
       "NO2          12\n",
       "NOx         334\n",
       "NH3          16\n",
       "CO           82\n",
       "SO2         140\n",
       "O3           85\n",
       "Benzene     189\n",
       "Toluene     206\n",
       "Xylene     1444\n",
       "AQI           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As per EDA, drop Benzene, Toluene, Xylene as these do not directly correlate with AQI and have significant numbers of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Benzene, Toluene, Xylene from data\n",
    "data.drop(['Benzene', 'Toluene', 'Xylene'], axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing Values using Iterative Imputer package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM2.5    0\n",
      "PM10     0\n",
      "NO       0\n",
      "NO2      0\n",
      "NOx      0\n",
      "NH3      0\n",
      "CO       0\n",
      "SO2      0\n",
      "O3       0\n",
      "AQI      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'City' and 'Date' column, as it's not used for imputation\n",
    "data_model = data.drop(['City', 'Date'], axis=1)\n",
    "\n",
    "# Initialize the Iterative Imputer with a RandomForestRegressor\n",
    "imputer = IterativeImputer(estimator=RandomForestRegressor(), max_iter=10, random_state=42)\n",
    "\n",
    "# Apply the imputer to the dataset\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(data_model), columns=data_model.columns)\n",
    "\n",
    "# Display information about missing values after imputation\n",
    "print(df_imputed.isnull().sum())\n",
    "\n",
    "# Merge the imputed dataframe and the dataset\n",
    "data_new = pd.concat([data[['City', 'Date']], df_imputed], axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Datasets\n",
    "amarvati = pd.read_csv('amarvati.csv')\n",
    "amritsar = pd.read_csv('amritsar.csv')\n",
    "jaipur = pd.read_csv('jaipur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Date' columns to datetime and remove timezones for consistency\n",
    "data_new['Date'] = pd.to_datetime(data_new['Date']).dt.tz_localize(None)\n",
    "amarvati['date'] = pd.to_datetime(amarvati['date']).dt.tz_localize(None)\n",
    "jaipur['date'] = pd.to_datetime(jaipur['date']).dt.tz_localize(None)\n",
    "amritsar['date'] = pd.to_datetime(amritsar['date']).dt.tz_localize(None)\n",
    "\n",
    "# Rename the 'date' columns to 'Date' for consistency\n",
    "amarvati.rename(columns={'date': 'Date'}, inplace=True)\n",
    "jaipur.rename(columns={'date': 'Date'}, inplace=True)\n",
    "amritsar.rename(columns={'date': 'Date'}, inplace=True)\n",
    "\n",
    "# Add the 'City' column to each weather dataset\n",
    "amarvati['City'] = 'Amaravati'\n",
    "jaipur['City'] = 'Jaipur'\n",
    "amritsar['City'] = 'Amritsar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity_max</th>\n",
       "      <th>dew_point_mean</th>\n",
       "      <th>dew_point_max</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>cloud_cover_sum</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_speed_100m_mean</th>\n",
       "      <th>wind_speed_100m_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>81.40</td>\n",
       "      <td>124.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.50</td>\n",
       "      <td>12.08</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>...</td>\n",
       "      <td>89.346016</td>\n",
       "      <td>19.013000</td>\n",
       "      <td>21.263000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>819.000009</td>\n",
       "      <td>9.180352</td>\n",
       "      <td>16.808570</td>\n",
       "      <td>15.935398</td>\n",
       "      <td>27.248455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>78.32</td>\n",
       "      <td>129.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.96</td>\n",
       "      <td>...</td>\n",
       "      <td>95.198590</td>\n",
       "      <td>18.248417</td>\n",
       "      <td>21.063000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.800023</td>\n",
       "      <td>7.759277</td>\n",
       "      <td>11.988594</td>\n",
       "      <td>14.097954</td>\n",
       "      <td>22.183128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>88.76</td>\n",
       "      <td>135.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>30.85</td>\n",
       "      <td>21.77</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>97.275760</td>\n",
       "      <td>18.960917</td>\n",
       "      <td>21.463001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.900014</td>\n",
       "      <td>6.287076</td>\n",
       "      <td>9.085988</td>\n",
       "      <td>11.361810</td>\n",
       "      <td>17.418196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>64.18</td>\n",
       "      <td>104.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.07</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.00</td>\n",
       "      <td>...</td>\n",
       "      <td>94.871315</td>\n",
       "      <td>17.425500</td>\n",
       "      <td>21.013000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.000013</td>\n",
       "      <td>7.019016</td>\n",
       "      <td>13.684735</td>\n",
       "      <td>13.233190</td>\n",
       "      <td>25.630886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>72.47</td>\n",
       "      <td>114.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>23.20</td>\n",
       "      <td>16.59</td>\n",
       "      <td>12.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10.55</td>\n",
       "      <td>...</td>\n",
       "      <td>96.376900</td>\n",
       "      <td>17.617167</td>\n",
       "      <td>20.663000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.000007</td>\n",
       "      <td>10.355873</td>\n",
       "      <td>14.186923</td>\n",
       "      <td>18.022025</td>\n",
       "      <td>23.904108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        City       Date  PM2.5    PM10    NO    NO2    NOx    NH3    CO  \\\n",
       "0  Amaravati 2017-11-25  81.40  124.50  1.44  20.50  12.08  10.72  0.12   \n",
       "1  Amaravati 2017-11-26  78.32  129.06  1.26  26.00  14.85  10.28  0.14   \n",
       "2  Amaravati 2017-11-27  88.76  135.32  6.60  30.85  21.77  12.91  0.11   \n",
       "3  Amaravati 2017-11-28  64.18  104.09  2.56  28.07  17.01  11.42  0.09   \n",
       "4  Amaravati 2017-11-29  72.47  114.84  5.23  23.20  16.59  12.25  0.16   \n",
       "\n",
       "     SO2  ...  humidity_max  dew_point_mean  dew_point_max  precipitation_sum  \\\n",
       "0  15.24  ...     89.346016       19.013000      21.263000                0.0   \n",
       "1  26.96  ...     95.198590       18.248417      21.063000                0.0   \n",
       "2  33.59  ...     97.275760       18.960917      21.463001                0.0   \n",
       "3  19.00  ...     94.871315       17.425500      21.013000                0.0   \n",
       "4  10.55  ...     96.376900       17.617167      20.663000                0.0   \n",
       "\n",
       "   rain_sum  cloud_cover_sum  wind_speed_10m_mean  wind_speed_10m_max  \\\n",
       "0       0.0       819.000009             9.180352           16.808570   \n",
       "1       0.0       532.800023             7.759277           11.988594   \n",
       "2       0.0       618.900014             6.287076            9.085988   \n",
       "3       0.0       378.000013             7.019016           13.684735   \n",
       "4       0.0       189.000007            10.355873           14.186923   \n",
       "\n",
       "   wind_speed_100m_mean  wind_speed_100m_max  \n",
       "0             15.935398            27.248455  \n",
       "1             14.097954            22.183128  \n",
       "2             11.361810            17.418196  \n",
       "3             13.233190            25.630886  \n",
       "4             18.022025            23.904108  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map cities to the correct city csv file\n",
    "city_data = {\n",
    "    'Amaravati': amarvati,\n",
    "    'Jaipur': jaipur,\n",
    "    'Amritsar': amritsar\n",
    "}\n",
    "\n",
    "# Initialise empty lists for storing new data\n",
    "temperature_mean = []\n",
    "temperature_max = []\n",
    "humidity_mean = []\n",
    "humidity_max = []\n",
    "dew_point_mean = []\n",
    "dew_point_max = []\n",
    "precipitation_sum = []\n",
    "rain_sum = []\n",
    "cloud_cover_sum = []\n",
    "wind_speed_10m_mean = []\n",
    "wind_speed_10m_max = []\n",
    "wind_speed_100m_mean = []\n",
    "wind_speed_100m_max = []\n",
    "\n",
    "# Loop over each row in data_new_df\n",
    "for index, row in data_new.iterrows():\n",
    "    city = row['City']\n",
    "    date = row['Date']\n",
    "    \n",
    "    # Check if the city has corresponding weather data\n",
    "    if city in city_data:\n",
    "        weather_df = city_data[city]\n",
    "        # Find the matching row in the city's weather DataFrame\n",
    "        match = weather_df[weather_df['Date'] == date]\n",
    "        \n",
    "        if not match.empty:\n",
    "            # Append values to the lists if a match is found\n",
    "            temperature_mean.append(match['temperature_mean'].values[0])\n",
    "            temperature_max.append(match['temperature_max'].values[0])\n",
    "            humidity_mean.append(match['humidity_mean'].values[0])\n",
    "            humidity_max.append(match['humidity_max'].values[0])\n",
    "            dew_point_mean.append(match['dew_point_mean'].values[0])\n",
    "            dew_point_max.append(match['dew_point_max'].values[0])\n",
    "            precipitation_sum.append(match['precipitation_sum'].values[0])\n",
    "            rain_sum.append(match['rain_sum'].values[0])\n",
    "            cloud_cover_sum.append(match['cloud_cover_sum'].values[0])\n",
    "            wind_speed_10m_mean.append(match['wind_speed_10m_mean'].values[0])\n",
    "            wind_speed_10m_max.append(match['wind_speed_10m_max'].values[0])\n",
    "            wind_speed_100m_mean.append(match['wind_speed_100m_mean'].values[0])\n",
    "            wind_speed_100m_max.append(match['wind_speed_100m_max'].values[0])\n",
    "        else:\n",
    "            # Append NaN if no match is found\n",
    "            temperature_mean.append(float('nan'))\n",
    "            temperature_max.append(float('nan'))\n",
    "            humidity_mean.append(float('nan'))\n",
    "            humidity_max.append(float('nan'))\n",
    "            dew_point_mean.append(float('nan'))\n",
    "            dew_point_max.append(float('nan'))\n",
    "            precipitation_sum.append(float('nan'))\n",
    "            rain_sum.append(float('nan'))\n",
    "            cloud_cover_sum.append(float('nan'))\n",
    "            wind_speed_10m_mean.append(float('nan'))\n",
    "            wind_speed_10m_max.append(float('nan'))\n",
    "            wind_speed_100m_mean.append(float('nan'))\n",
    "            wind_speed_100m_max.append(float('nan'))\n",
    "    else:\n",
    "        # Append NaN if no matching city is found\n",
    "        temperature_mean.append(float('nan'))\n",
    "        temperature_max.append(float('nan'))\n",
    "        humidity_mean.append(float('nan'))\n",
    "        humidity_max.append(float('nan'))\n",
    "        dew_point_mean.append(float('nan'))\n",
    "        dew_point_max.append(float('nan'))\n",
    "        precipitation_sum.append(float('nan'))\n",
    "        rain_sum.append(float('nan'))\n",
    "        cloud_cover_sum.append(float('nan'))\n",
    "        wind_speed_10m_mean.append(float('nan'))\n",
    "        wind_speed_10m_max.append(float('nan'))\n",
    "        wind_speed_100m_mean.append(float('nan'))\n",
    "        wind_speed_100m_max.append(float('nan'))\n",
    "\n",
    "# Add the new data to the DataFrame\n",
    "data_new['temperature_mean'] = temperature_mean\n",
    "data_new['temperature_max'] = temperature_max\n",
    "data_new['humidity_mean'] = humidity_mean\n",
    "data_new['humidity_max'] = humidity_max\n",
    "data_new['dew_point_mean'] = dew_point_mean\n",
    "data_new['dew_point_max'] = dew_point_max\n",
    "data_new['precipitation_sum'] = precipitation_sum\n",
    "data_new['rain_sum'] = rain_sum\n",
    "data_new['cloud_cover_sum'] = cloud_cover_sum\n",
    "data_new['wind_speed_10m_mean'] = wind_speed_10m_mean\n",
    "data_new['wind_speed_10m_max'] = wind_speed_10m_max\n",
    "data_new['wind_speed_100m_mean'] = wind_speed_100m_mean\n",
    "data_new['wind_speed_100m_max'] = wind_speed_100m_max\n",
    "\n",
    "data_new.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Ridge & Lasso Regression to examine features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = data_new[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'temperature_mean', 'temperature_max', 'humidity_mean', 'humidity_max', 'dew_point_mean', 'dew_point_max', 'precipitation_sum', 'rain_sum', 'cloud_cover_sum', 'wind_speed_10m_mean', 'wind_speed_10m_max', 'wind_speed_100m_mean', 'wind_speed_100m_max']]\n",
    "y = data_new['AQI'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 714.8898354682925\n",
      "R-squared: 0.8103402340221986\n",
      "                 Feature  Coefficient\n",
      "0                  PM2.5      18.9347\n",
      "1                   PM10      42.8007\n",
      "2                     NO       3.6300\n",
      "3                    NO2       4.9075\n",
      "4                    NOx      -3.1024\n",
      "5                    NH3      -2.1381\n",
      "6                     CO       3.5156\n",
      "7                    SO2       0.0098\n",
      "8                     O3       6.4020\n",
      "9       temperature_mean       0.4286\n",
      "10       temperature_max       0.2653\n",
      "11         humidity_mean       2.2322\n",
      "12          humidity_max       1.8805\n",
      "13        dew_point_mean       3.8574\n",
      "14         dew_point_max      -5.5988\n",
      "15     precipitation_sum      -0.1931\n",
      "16              rain_sum      -0.1931\n",
      "17       cloud_cover_sum       0.3614\n",
      "18   wind_speed_10m_mean       1.9838\n",
      "19    wind_speed_10m_max      -1.9164\n",
      "20  wind_speed_100m_mean       0.2510\n",
      "21   wind_speed_100m_max       1.5511\n",
      "Cross-validated MSE (for each fold): [ 784.52547307 2116.97481154 1079.15688496  772.86518985  616.33961945]\n",
      "Average MSE: 1073.972395772015\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardise both sets of data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initiate Ridge Regression\n",
    "ridge = Ridge(alpha=1) \n",
    "\n",
    "# Fit the model\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(ridge.coef_,4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)\n",
    "\n",
    "ridge_cv = cross_val_score(ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -ridge_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -ridge_cv.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Ridge: 100\n",
      "Mean Squared Error: 707.5100734480131\n",
      "R-squared: 0.8122980796486107\n",
      "                 Feature  Coefficient\n",
      "0                  PM2.5      19.4432\n",
      "1                   PM10      40.2657\n",
      "2                     NO       2.6897\n",
      "3                    NO2       4.0629\n",
      "4                    NOx      -0.9479\n",
      "5                    NH3      -1.8538\n",
      "6                     CO       3.6153\n",
      "7                    SO2       0.0118\n",
      "8                     O3       6.3902\n",
      "9       temperature_mean      -0.1859\n",
      "10       temperature_max      -0.2634\n",
      "11         humidity_mean       1.5428\n",
      "12          humidity_max       1.7248\n",
      "13        dew_point_mean       1.5592\n",
      "14         dew_point_max      -2.2813\n",
      "15     precipitation_sum      -0.1358\n",
      "16              rain_sum      -0.1358\n",
      "17       cloud_cover_sum       0.0766\n",
      "18   wind_speed_10m_mean       1.1943\n",
      "19    wind_speed_10m_max      -1.1653\n",
      "20  wind_speed_100m_mean       0.6718\n",
      "21   wind_speed_100m_max       0.9361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the alpha values to test for tuning\n",
    "alpha_values = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Initiate Ridge Regression and GridSearchCV\n",
    "ridge = Ridge()\n",
    "\n",
    "# Use GridSearchCV to tune alpha\n",
    "ridge_cv = GridSearchCV(ridge, alpha_values, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best alpha value\n",
    "best_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Ridge: {best_alpha}\")\n",
    "\n",
    "# Use the best alpha to fit the model again\n",
    "ridge_best = Ridge(alpha=best_alpha)\n",
    "ridge_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge_best.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge_best.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(ridge_best.coef_, 4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 712.5025526103241\n",
      "R-squared: 0.8109735784701142\n",
      "                 Feature  Coefficient\n",
      "0                  PM2.5      18.9287\n",
      "1                   PM10      42.7005\n",
      "2                     NO       2.5704\n",
      "3                    NO2       3.9986\n",
      "4                    NOx      -1.4336\n",
      "5                    NH3      -1.9465\n",
      "6                     CO       3.3648\n",
      "7                    SO2       0.0589\n",
      "8                     O3       6.3345\n",
      "9       temperature_mean      -0.0000\n",
      "10       temperature_max      -0.0000\n",
      "11         humidity_mean       2.4365\n",
      "12          humidity_max       1.3955\n",
      "13        dew_point_mean       0.0000\n",
      "14         dew_point_max      -1.2038\n",
      "15     precipitation_sum      -0.1671\n",
      "16              rain_sum      -0.0000\n",
      "17       cloud_cover_sum       0.1569\n",
      "18   wind_speed_10m_mean       0.4005\n",
      "19    wind_speed_10m_max      -0.3085\n",
      "20  wind_speed_100m_mean       1.5533\n",
      "21   wind_speed_100m_max       0.0870\n",
      "Cross-validated MSE (for each fold): [ 780.55316302 2120.16378291 1077.9697702   769.92500813  610.27408258]\n",
      "Average MSE: 1071.7771613662178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Using majority of the same code as above:\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = lasso.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(lasso.coef_,4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)\n",
    "\n",
    "lasso_cv = cross_val_score(lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -lasso_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -lasso_cv.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Lasso: 1\n",
      "Mean Squared Error: 707.4988197108421\n",
      "R-squared: 0.8122980796486107\n",
      "                 Feature  Coefficient\n",
      "0                  PM2.5      18.2336\n",
      "1                   PM10      42.3349\n",
      "2                     NO       0.4797\n",
      "3                    NO2       2.4446\n",
      "4                    NOx       0.0000\n",
      "5                    NH3      -0.0000\n",
      "6                     CO       2.8539\n",
      "7                    SO2       0.0000\n",
      "8                     O3       5.0229\n",
      "9       temperature_mean      -0.0000\n",
      "10       temperature_max      -1.1287\n",
      "11         humidity_mean       0.0000\n",
      "12          humidity_max       1.2888\n",
      "13        dew_point_mean      -0.0000\n",
      "14         dew_point_max      -0.0000\n",
      "15     precipitation_sum       0.0000\n",
      "16              rain_sum       0.0000\n",
      "17       cloud_cover_sum       0.0000\n",
      "18   wind_speed_10m_mean       0.0000\n",
      "19    wind_speed_10m_max       0.0000\n",
      "20  wind_speed_100m_mean       0.2584\n",
      "21   wind_speed_100m_max       0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the alpha values to test for tuning\n",
    "alpha_values = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Initiate Ridge Regression and GridSearchCV\n",
    "lasso = Lasso()\n",
    "\n",
    "# Use GridSearchCV to tune alpha\n",
    "lasso_cv = GridSearchCV(lasso, alpha_values, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best alpha value\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Lasso: {best_alpha}\")\n",
    "\n",
    "# Use the best alpha to fit the model again\n",
    "lasso_best = Lasso(alpha=best_alpha)\n",
    "lasso_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lasso_best.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge_best.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(lasso_best.coef_, 4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As PM2.5 particles are included in PM10, we face the issue of multicolinearity. By applying PCA onto these features we can reduce this.\n",
    "\n",
    "- This improves the Ridge and Lasso Regression models but will sacrifice interpretability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio: [0.85227251 0.14772749]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8h/gtndp3dj3pl2vs4brgn9zq9h0000gp/T/ipykernel_33250/408682948.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.drop(['PM2.5', 'PM10'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "pm_data_scaled = scaler.fit_transform(data_new[['PM2.5', 'PM10']])\n",
    "\n",
    "# Step 2: Apply PCA to PM2.5 and PM10\n",
    "pca = PCA(n_components=2)  # Use 2 components because we have 2 features\n",
    "pm_pca = pca.fit_transform(pm_data_scaled)\n",
    "\n",
    "# Create a new DataFrame with the principal components\n",
    "pm_pca_df = pd.DataFrame(pm_pca, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Explained variance to understand how much information is captured by each component\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance Ratio: {explained_variance}\")\n",
    "\n",
    "# Keep PC1 and drop both PM2.5 and PM10\n",
    "X.drop(['PM2.5', 'PM10'], axis=1, inplace=True)\n",
    "\n",
    "# Add PC1\n",
    "X.insert(0, 'PC1', pm_pca[:, 0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 627.1008777524146\n",
      "R-squared: 0.8336305821986023\n",
      "                 Feature  Coefficient\n",
      "0                    PC1      55.8033\n",
      "1                     NO       3.5722\n",
      "2                    NO2       4.8283\n",
      "3                    NOx      -1.7277\n",
      "4                    NH3      -2.5497\n",
      "5                     CO       4.7139\n",
      "6                    SO2      -1.3840\n",
      "7                     O3       7.1235\n",
      "8       temperature_mean      -5.7314\n",
      "9        temperature_max       0.8435\n",
      "10         humidity_mean      -1.5633\n",
      "11          humidity_max       1.3196\n",
      "12        dew_point_mean       8.5230\n",
      "13         dew_point_max      -3.1947\n",
      "14     precipitation_sum       0.0885\n",
      "15              rain_sum       0.0885\n",
      "16       cloud_cover_sum      -0.8548\n",
      "17   wind_speed_10m_mean       2.5595\n",
      "18    wind_speed_10m_max      -1.6153\n",
      "19  wind_speed_100m_mean      -0.9256\n",
      "20   wind_speed_100m_max       2.4149\n",
      "Cross-validated MSE (for each fold): [ 665.88083357 1811.90704613 1182.85104781  705.57631079  527.500216  ]\n",
      "Average MSE: 978.7430908606077\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardise both sets of data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initiate Ridge Regression\n",
    "ridge = Ridge(alpha=1.0) \n",
    "\n",
    "# Fit the model\n",
    "ridge.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(ridge.coef_,4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)\n",
    "\n",
    "ridge_cv = cross_val_score(ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -ridge_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -ridge_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Ridge: 10\n",
      "Mean Squared Error: 627.8042929064565\n",
      "R-squared: 0.8334439666574631\n",
      "                 Feature  Coefficient\n",
      "0                    PC1      55.5202\n",
      "1                     NO       3.4941\n",
      "2                    NO2       4.7450\n",
      "3                    NOx      -1.4831\n",
      "4                    NH3      -2.5204\n",
      "5                     CO       4.7188\n",
      "6                    SO2      -1.3633\n",
      "7                     O3       7.1369\n",
      "8       temperature_mean      -3.2007\n",
      "9        temperature_max       0.1325\n",
      "10         humidity_mean      -0.2417\n",
      "11          humidity_max       1.4172\n",
      "12        dew_point_mean       6.1475\n",
      "13         dew_point_max      -2.8251\n",
      "14     precipitation_sum       0.0636\n",
      "15              rain_sum       0.0636\n",
      "16       cloud_cover_sum      -1.0095\n",
      "17   wind_speed_10m_mean       2.4161\n",
      "18    wind_speed_10m_max      -1.4726\n",
      "19  wind_speed_100m_mean      -0.7773\n",
      "20   wind_speed_100m_max       2.2802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the alpha values to test for tuning\n",
    "alpha_values = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Initiate Ridge Regression and GridSearchCV\n",
    "ridge = Ridge()\n",
    "\n",
    "# Use GridSearchCV to tune alpha\n",
    "ridge_cv = GridSearchCV(ridge, alpha_values, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best alpha value\n",
    "best_alpha = ridge_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Ridge: {best_alpha}\")\n",
    "\n",
    "# Use the best alpha to fit the model again\n",
    "ridge_best = Ridge(alpha=best_alpha)\n",
    "ridge_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = ridge_best.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge_best.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(ridge_best.coef_, 4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 624.4432369731543\n",
      "R-squared: 0.834335652411158\n",
      "                 Feature  Coefficient\n",
      "0                    PC1      55.7421\n",
      "1                     NO       2.6461\n",
      "2                    NO2       3.8814\n",
      "3                    NOx      -0.0000\n",
      "4                    NH3      -2.3965\n",
      "5                     CO       4.4967\n",
      "6                    SO2      -1.1468\n",
      "7                     O3       7.0591\n",
      "8       temperature_mean      -0.0221\n",
      "9        temperature_max      -0.4304\n",
      "10         humidity_mean       1.7901\n",
      "11          humidity_max       1.3792\n",
      "12        dew_point_mean       0.4521\n",
      "13         dew_point_max      -0.0000\n",
      "14     precipitation_sum      -0.0000\n",
      "15              rain_sum      -0.0000\n",
      "16       cloud_cover_sum      -0.7377\n",
      "17   wind_speed_10m_mean       1.2547\n",
      "18    wind_speed_10m_max      -0.2035\n",
      "19  wind_speed_100m_mean       0.1649\n",
      "20   wind_speed_100m_max       1.0949\n",
      "Cross-validated MSE (for each fold): [ 662.18637073 1814.63523434 1182.72703608  701.45804575  522.66823632]\n",
      "Average MSE: 976.7349846432911\n"
     ]
    }
   ],
   "source": [
    "# Using majority of the same code as above:\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = lasso.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(lasso.coef_,4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)\n",
    "\n",
    "lasso_cv = cross_val_score(lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "                           \n",
    "# Output the results (MSE for each fold)\n",
    "print(\"Cross-validated MSE (for each fold):\", -lasso_cv)\n",
    "\n",
    "# Mean of the cross-validation scores\n",
    "print(\"Average MSE:\", -lasso_cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha for Lasso: 0.1\n",
      "Mean Squared Error: 624.4432369731543\n",
      "R-squared: 0.8334439666574631\n",
      "                 Feature  Coefficient\n",
      "0                    PC1      55.7421\n",
      "1                     NO       2.6461\n",
      "2                    NO2       3.8814\n",
      "3                    NOx      -0.0000\n",
      "4                    NH3      -2.3965\n",
      "5                     CO       4.4967\n",
      "6                    SO2      -1.1468\n",
      "7                     O3       7.0591\n",
      "8       temperature_mean      -0.0221\n",
      "9        temperature_max      -0.4304\n",
      "10         humidity_mean       1.7901\n",
      "11          humidity_max       1.3792\n",
      "12        dew_point_mean       0.4521\n",
      "13         dew_point_max      -0.0000\n",
      "14     precipitation_sum      -0.0000\n",
      "15              rain_sum      -0.0000\n",
      "16       cloud_cover_sum      -0.7377\n",
      "17   wind_speed_10m_mean       1.2547\n",
      "18    wind_speed_10m_max      -0.2035\n",
      "19  wind_speed_100m_mean       0.1649\n",
      "20   wind_speed_100m_max       1.0949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the alpha values to test for tuning\n",
    "alpha_values = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]}\n",
    "\n",
    "# Initiate Ridge Regression and GridSearchCV\n",
    "lasso = Lasso()\n",
    "\n",
    "# Use GridSearchCV to tune alpha\n",
    "lasso_cv = GridSearchCV(lasso, alpha_values, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best alpha value\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "print(f\"Best alpha for Lasso: {best_alpha}\")\n",
    "\n",
    "# Use the best alpha to fit the model again\n",
    "lasso_best = Lasso(alpha=best_alpha)\n",
    "lasso_best.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lasso_best.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = ridge_best.score(X_test_scaled, y_test)\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "\n",
    "# Print Coefficients as table\n",
    "feature_names = X.columns\n",
    "coefficients = np.round(lasso_best.coef_, 4)\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From here we can look to remove x,y and z features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based off of Ridge & Lasso Regression, we can remove certain components\n",
    "columns_to_drop = ['NOx', 'temperature_mean', 'dew_point_max', 'precipitation_sum', 'rain_sum', 'wind_speed_100m_mean', 'wind_speed_10m_max', 'temperature_max', 'dew_point_mean'] # Removing all zeroed components & any low coefficient features\n",
    "\n",
    "# Drop columns on original data\n",
    "#model_data = data_new.drop(columns_to_drop, axis=1) # This data does not include Principle Component Analysis\n",
    "\n",
    "# Apply Principle Component to original data and drop columns\n",
    "model_data = data_new.drop(['PM2.5', 'PM10'], axis=1)\n",
    "# Add PC1\n",
    "model_data.insert(2, 'PC1', pm_pca[:, 0])\n",
    "model_data.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PC1</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>AQI</th>\n",
       "      <th>humidity_mean</th>\n",
       "      <th>humidity_max</th>\n",
       "      <th>cloud_cover_sum</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>wind_speed_100m_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>0.823624</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.5</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>127.09</td>\n",
       "      <td>184.0</td>\n",
       "      <td>64.906533</td>\n",
       "      <td>89.346016</td>\n",
       "      <td>819.000009</td>\n",
       "      <td>9.180352</td>\n",
       "      <td>27.248455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        City       Date       PC1    NO   NO2    NH3    CO    SO2      O3  \\\n",
       "0  Amaravati 2017-11-25  0.823624  1.44  20.5  10.72  0.12  15.24  127.09   \n",
       "\n",
       "     AQI  humidity_mean  humidity_max  cloud_cover_sum  wind_speed_10m_mean  \\\n",
       "0  184.0      64.906533     89.346016       819.000009             9.180352   \n",
       "\n",
       "   wind_speed_100m_max  \n",
       "0            27.248455  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.to_csv('model_data.csv', index=True)\n",
    "\n",
    "model_data.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTER for Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='AQI', ylabel='Count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of AQI\n",
    "sns.histplot(model_data['AQI'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 432/432 [00:17<00:00, 25.26it/s]\n",
      "synth_matrix: 100%|##########| 432/432 [00:01<00:00, 346.96it/s]\n",
      "r_index: 100%|##########| 43/43 [00:00<00:00, 1725.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4739, 15) (3061, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import smogn\n",
    "\n",
    "# Implement SMOTER to synthesise extreme data points due to skewness of AQI\n",
    "model_data_smoter = smogn.smoter(data=model_data,y='AQI', samp_method='extreme')\n",
    "\n",
    "# Print sizes of dataframe\n",
    "print(model_data_smoter.shape, data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>...</th>\n",
       "      <th>humidity_max</th>\n",
       "      <th>dew_point_mean</th>\n",
       "      <th>dew_point_max</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>cloud_cover_sum</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_speed_100m_mean</th>\n",
       "      <th>wind_speed_100m_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>81.40</td>\n",
       "      <td>124.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.50</td>\n",
       "      <td>12.08</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>...</td>\n",
       "      <td>89.346016</td>\n",
       "      <td>19.013000</td>\n",
       "      <td>21.263000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>819.000009</td>\n",
       "      <td>9.180352</td>\n",
       "      <td>16.808570</td>\n",
       "      <td>15.935398</td>\n",
       "      <td>27.248455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>78.32</td>\n",
       "      <td>129.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.96</td>\n",
       "      <td>...</td>\n",
       "      <td>95.198590</td>\n",
       "      <td>18.248417</td>\n",
       "      <td>21.063000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.800023</td>\n",
       "      <td>7.759277</td>\n",
       "      <td>11.988594</td>\n",
       "      <td>14.097954</td>\n",
       "      <td>22.183128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>88.76</td>\n",
       "      <td>135.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>30.85</td>\n",
       "      <td>21.77</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>97.275760</td>\n",
       "      <td>18.960917</td>\n",
       "      <td>21.463001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>618.900014</td>\n",
       "      <td>6.287076</td>\n",
       "      <td>9.085988</td>\n",
       "      <td>11.361810</td>\n",
       "      <td>17.418196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>64.18</td>\n",
       "      <td>104.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.07</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.00</td>\n",
       "      <td>...</td>\n",
       "      <td>94.871315</td>\n",
       "      <td>17.425500</td>\n",
       "      <td>21.013000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.000013</td>\n",
       "      <td>7.019016</td>\n",
       "      <td>13.684735</td>\n",
       "      <td>13.233190</td>\n",
       "      <td>25.630886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>72.47</td>\n",
       "      <td>114.84</td>\n",
       "      <td>5.23</td>\n",
       "      <td>23.20</td>\n",
       "      <td>16.59</td>\n",
       "      <td>12.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>10.55</td>\n",
       "      <td>...</td>\n",
       "      <td>96.376900</td>\n",
       "      <td>17.617167</td>\n",
       "      <td>20.663000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>189.000007</td>\n",
       "      <td>10.355873</td>\n",
       "      <td>14.186923</td>\n",
       "      <td>18.022025</td>\n",
       "      <td>23.904108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>28.33</td>\n",
       "      <td>76.66</td>\n",
       "      <td>6.15</td>\n",
       "      <td>14.72</td>\n",
       "      <td>18.14</td>\n",
       "      <td>21.82</td>\n",
       "      <td>0.59</td>\n",
       "      <td>9.96</td>\n",
       "      <td>...</td>\n",
       "      <td>92.568756</td>\n",
       "      <td>24.902417</td>\n",
       "      <td>25.704500</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1160.500034</td>\n",
       "      <td>13.700709</td>\n",
       "      <td>20.873790</td>\n",
       "      <td>23.140423</td>\n",
       "      <td>28.963785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>23.76</td>\n",
       "      <td>67.44</td>\n",
       "      <td>5.60</td>\n",
       "      <td>14.05</td>\n",
       "      <td>17.20</td>\n",
       "      <td>20.41</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.93</td>\n",
       "      <td>...</td>\n",
       "      <td>93.412636</td>\n",
       "      <td>24.931583</td>\n",
       "      <td>26.154501</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1071.400025</td>\n",
       "      <td>10.698332</td>\n",
       "      <td>18.079027</td>\n",
       "      <td>18.079032</td>\n",
       "      <td>30.007679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>30.58</td>\n",
       "      <td>77.30</td>\n",
       "      <td>6.21</td>\n",
       "      <td>16.63</td>\n",
       "      <td>19.50</td>\n",
       "      <td>22.70</td>\n",
       "      <td>0.55</td>\n",
       "      <td>10.59</td>\n",
       "      <td>...</td>\n",
       "      <td>97.047820</td>\n",
       "      <td>24.685750</td>\n",
       "      <td>25.854500</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1164.600019</td>\n",
       "      <td>6.531334</td>\n",
       "      <td>12.181625</td>\n",
       "      <td>11.079909</td>\n",
       "      <td>19.453327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>30.03</td>\n",
       "      <td>64.26</td>\n",
       "      <td>5.48</td>\n",
       "      <td>13.77</td>\n",
       "      <td>16.94</td>\n",
       "      <td>19.79</td>\n",
       "      <td>0.67</td>\n",
       "      <td>10.36</td>\n",
       "      <td>...</td>\n",
       "      <td>95.913940</td>\n",
       "      <td>24.933667</td>\n",
       "      <td>25.604500</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1011.899999</td>\n",
       "      <td>6.160173</td>\n",
       "      <td>10.703569</td>\n",
       "      <td>11.155103</td>\n",
       "      <td>16.935310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>58.79</td>\n",
       "      <td>103.68</td>\n",
       "      <td>5.19</td>\n",
       "      <td>10.88</td>\n",
       "      <td>14.16</td>\n",
       "      <td>17.41</td>\n",
       "      <td>0.54</td>\n",
       "      <td>5.19</td>\n",
       "      <td>...</td>\n",
       "      <td>93.132630</td>\n",
       "      <td>25.017000</td>\n",
       "      <td>26.354500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>925.200020</td>\n",
       "      <td>10.063586</td>\n",
       "      <td>13.104198</td>\n",
       "      <td>17.222742</td>\n",
       "      <td>24.192429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3061 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City       Date  PM2.5    PM10    NO    NO2    NOx    NH3    CO  \\\n",
       "0     Amaravati 2017-11-25  81.40  124.50  1.44  20.50  12.08  10.72  0.12   \n",
       "1     Amaravati 2017-11-26  78.32  129.06  1.26  26.00  14.85  10.28  0.14   \n",
       "2     Amaravati 2017-11-27  88.76  135.32  6.60  30.85  21.77  12.91  0.11   \n",
       "3     Amaravati 2017-11-28  64.18  104.09  2.56  28.07  17.01  11.42  0.09   \n",
       "4     Amaravati 2017-11-29  72.47  114.84  5.23  23.20  16.59  12.25  0.16   \n",
       "...         ...        ...    ...     ...   ...    ...    ...    ...   ...   \n",
       "3056     Jaipur 2020-06-27  28.33   76.66  6.15  14.72  18.14  21.82  0.59   \n",
       "3057     Jaipur 2020-06-28  23.76   67.44  5.60  14.05  17.20  20.41  0.50   \n",
       "3058     Jaipur 2020-06-29  30.58   77.30  6.21  16.63  19.50  22.70  0.55   \n",
       "3059     Jaipur 2020-06-30  30.03   64.26  5.48  13.77  16.94  19.79  0.67   \n",
       "3060     Jaipur 2020-07-01  58.79  103.68  5.19  10.88  14.16  17.41  0.54   \n",
       "\n",
       "        SO2  ...  humidity_max  dew_point_mean  dew_point_max  \\\n",
       "0     15.24  ...     89.346016       19.013000      21.263000   \n",
       "1     26.96  ...     95.198590       18.248417      21.063000   \n",
       "2     33.59  ...     97.275760       18.960917      21.463001   \n",
       "3     19.00  ...     94.871315       17.425500      21.013000   \n",
       "4     10.55  ...     96.376900       17.617167      20.663000   \n",
       "...     ...  ...           ...             ...            ...   \n",
       "3056   9.96  ...     92.568756       24.902417      25.704500   \n",
       "3057   8.93  ...     93.412636       24.931583      26.154501   \n",
       "3058  10.59  ...     97.047820       24.685750      25.854500   \n",
       "3059  10.36  ...     95.913940       24.933667      25.604500   \n",
       "3060   5.19  ...     93.132630       25.017000      26.354500   \n",
       "\n",
       "      precipitation_sum  rain_sum  cloud_cover_sum  wind_speed_10m_mean  \\\n",
       "0                   0.0       0.0       819.000009             9.180352   \n",
       "1                   0.0       0.0       532.800023             7.759277   \n",
       "2                   0.0       0.0       618.900014             6.287076   \n",
       "3                   0.0       0.0       378.000013             7.019016   \n",
       "4                   0.0       0.0       189.000007            10.355873   \n",
       "...                 ...       ...              ...                  ...   \n",
       "3056                2.6       2.6      1160.500034            13.700709   \n",
       "3057               10.3      10.3      1071.400025            10.698332   \n",
       "3058                7.3       7.3      1164.600019             6.531334   \n",
       "3059                2.2       2.2      1011.899999             6.160173   \n",
       "3060                1.0       1.0       925.200020            10.063586   \n",
       "\n",
       "      wind_speed_10m_max  wind_speed_100m_mean  wind_speed_100m_max  \n",
       "0              16.808570             15.935398            27.248455  \n",
       "1              11.988594             14.097954            22.183128  \n",
       "2               9.085988             11.361810            17.418196  \n",
       "3              13.684735             13.233190            25.630886  \n",
       "4              14.186923             18.022025            23.904108  \n",
       "...                  ...                   ...                  ...  \n",
       "3056           20.873790             23.140423            28.963785  \n",
       "3057           18.079027             18.079032            30.007679  \n",
       "3058           12.181625             11.079909            19.453327  \n",
       "3059           10.703569             11.155103            16.935310  \n",
       "3060           13.104198             17.222742            24.192429  \n",
       "\n",
       "[3061 rows x 25 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>PC1</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>AQI</th>\n",
       "      <th>humidity_mean</th>\n",
       "      <th>humidity_max</th>\n",
       "      <th>cloud_cover_sum</th>\n",
       "      <th>wind_speed_10m_mean</th>\n",
       "      <th>wind_speed_100m_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2018-12-04 04:31:06.220569600</td>\n",
       "      <td>1.380233</td>\n",
       "      <td>4.139891</td>\n",
       "      <td>87.230046</td>\n",
       "      <td>1.856056</td>\n",
       "      <td>1.122237</td>\n",
       "      <td>13.502333</td>\n",
       "      <td>33.040825</td>\n",
       "      <td>208.787600</td>\n",
       "      <td>67.728518</td>\n",
       "      <td>82.397022</td>\n",
       "      <td>1765.715600</td>\n",
       "      <td>10.490651</td>\n",
       "      <td>23.520370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2018-12-03 18:11:19.203663616</td>\n",
       "      <td>1.343673</td>\n",
       "      <td>4.115828</td>\n",
       "      <td>87.033134</td>\n",
       "      <td>1.577710</td>\n",
       "      <td>1.126143</td>\n",
       "      <td>13.704345</td>\n",
       "      <td>33.368187</td>\n",
       "      <td>193.554987</td>\n",
       "      <td>67.364475</td>\n",
       "      <td>82.191324</td>\n",
       "      <td>1770.745571</td>\n",
       "      <td>10.607287</td>\n",
       "      <td>23.829322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2018-12-12 22:19:42.468012800</td>\n",
       "      <td>1.625765</td>\n",
       "      <td>3.472994</td>\n",
       "      <td>63.260210</td>\n",
       "      <td>15.126610</td>\n",
       "      <td>1.101881</td>\n",
       "      <td>21.892754</td>\n",
       "      <td>38.485634</td>\n",
       "      <td>194.361323</td>\n",
       "      <td>50.525091</td>\n",
       "      <td>78.062946</td>\n",
       "      <td>1282.263607</td>\n",
       "      <td>11.408205</td>\n",
       "      <td>23.189387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2018-12-06 13:06:29.097780480</td>\n",
       "      <td>1.514465</td>\n",
       "      <td>4.395540</td>\n",
       "      <td>91.575542</td>\n",
       "      <td>5.585385</td>\n",
       "      <td>0.812947</td>\n",
       "      <td>11.277523</td>\n",
       "      <td>28.752434</td>\n",
       "      <td>191.054849</td>\n",
       "      <td>74.821580</td>\n",
       "      <td>91.565805</td>\n",
       "      <td>1025.465271</td>\n",
       "      <td>7.912814</td>\n",
       "      <td>17.744277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amaravati</td>\n",
       "      <td>2018-12-11 09:55:15.554727680</td>\n",
       "      <td>1.579364</td>\n",
       "      <td>3.577803</td>\n",
       "      <td>67.284339</td>\n",
       "      <td>12.815287</td>\n",
       "      <td>1.103261</td>\n",
       "      <td>20.487481</td>\n",
       "      <td>37.558898</td>\n",
       "      <td>194.361323</td>\n",
       "      <td>53.404399</td>\n",
       "      <td>78.726746</td>\n",
       "      <td>1371.365388</td>\n",
       "      <td>11.283131</td>\n",
       "      <td>23.311255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-27 00:00:00</td>\n",
       "      <td>-0.772288</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>14.720000</td>\n",
       "      <td>21.820000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>9.960000</td>\n",
       "      <td>39.120000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>82.146618</td>\n",
       "      <td>92.568756</td>\n",
       "      <td>1160.500034</td>\n",
       "      <td>13.700709</td>\n",
       "      <td>28.963785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-28 00:00:00</td>\n",
       "      <td>-0.967482</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>14.050000</td>\n",
       "      <td>20.410000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.930000</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>85.573320</td>\n",
       "      <td>93.412636</td>\n",
       "      <td>1071.400025</td>\n",
       "      <td>10.698332</td>\n",
       "      <td>30.007679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-29 00:00:00</td>\n",
       "      <td>-0.720350</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>16.630000</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>39.210000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>84.936178</td>\n",
       "      <td>97.047820</td>\n",
       "      <td>1164.600019</td>\n",
       "      <td>6.531334</td>\n",
       "      <td>19.453327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-06-30 00:00:00</td>\n",
       "      <td>-0.878962</td>\n",
       "      <td>5.480000</td>\n",
       "      <td>13.770000</td>\n",
       "      <td>19.790000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>10.360000</td>\n",
       "      <td>50.710000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>84.108397</td>\n",
       "      <td>95.913940</td>\n",
       "      <td>1011.899999</td>\n",
       "      <td>6.160173</td>\n",
       "      <td>16.935310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3060</th>\n",
       "      <td>Jaipur</td>\n",
       "      <td>2020-07-01 00:00:00</td>\n",
       "      <td>0.138737</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>10.880000</td>\n",
       "      <td>17.410000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>53.680000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>77.781180</td>\n",
       "      <td>93.132630</td>\n",
       "      <td>925.200020</td>\n",
       "      <td>10.063586</td>\n",
       "      <td>24.192429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4739 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           City                           Date       PC1        NO        NO2  \\\n",
       "0     Amaravati  2018-12-04 04:31:06.220569600  1.380233  4.139891  87.230046   \n",
       "1     Amaravati  2018-12-03 18:11:19.203663616  1.343673  4.115828  87.033134   \n",
       "2     Amaravati  2018-12-12 22:19:42.468012800  1.625765  3.472994  63.260210   \n",
       "3     Amaravati  2018-12-06 13:06:29.097780480  1.514465  4.395540  91.575542   \n",
       "4     Amaravati  2018-12-11 09:55:15.554727680  1.579364  3.577803  67.284339   \n",
       "...         ...                            ...       ...       ...        ...   \n",
       "3056     Jaipur            2020-06-27 00:00:00 -0.772288  6.150000  14.720000   \n",
       "3057     Jaipur            2020-06-28 00:00:00 -0.967482  5.600000  14.050000   \n",
       "3058     Jaipur            2020-06-29 00:00:00 -0.720350  6.210000  16.630000   \n",
       "3059     Jaipur            2020-06-30 00:00:00 -0.878962  5.480000  13.770000   \n",
       "3060     Jaipur            2020-07-01 00:00:00  0.138737  5.190000  10.880000   \n",
       "\n",
       "            NH3        CO        SO2         O3         AQI  humidity_mean  \\\n",
       "0      1.856056  1.122237  13.502333  33.040825  208.787600      67.728518   \n",
       "1      1.577710  1.126143  13.704345  33.368187  193.554987      67.364475   \n",
       "2     15.126610  1.101881  21.892754  38.485634  194.361323      50.525091   \n",
       "3      5.585385  0.812947  11.277523  28.752434  191.054849      74.821580   \n",
       "4     12.815287  1.103261  20.487481  37.558898  194.361323      53.404399   \n",
       "...         ...       ...        ...        ...         ...            ...   \n",
       "3056  21.820000  0.590000   9.960000  39.120000   89.000000      82.146618   \n",
       "3057  20.410000  0.500000   8.930000  34.400000   75.000000      85.573320   \n",
       "3058  22.700000  0.550000  10.590000  39.210000   69.000000      84.936178   \n",
       "3059  19.790000  0.670000  10.360000  50.710000   79.000000      84.108397   \n",
       "3060  17.410000  0.540000   5.190000  53.680000   70.000000      77.781180   \n",
       "\n",
       "      humidity_max  cloud_cover_sum  wind_speed_10m_mean  wind_speed_100m_max  \n",
       "0        82.397022      1765.715600            10.490651            23.520370  \n",
       "1        82.191324      1770.745571            10.607287            23.829322  \n",
       "2        78.062946      1282.263607            11.408205            23.189387  \n",
       "3        91.565805      1025.465271             7.912814            17.744277  \n",
       "4        78.726746      1371.365388            11.283131            23.311255  \n",
       "...            ...              ...                  ...                  ...  \n",
       "3056     92.568756      1160.500034            13.700709            28.963785  \n",
       "3057     93.412636      1071.400025            10.698332            30.007679  \n",
       "3058     97.047820      1164.600019             6.531334            19.453327  \n",
       "3059     95.913940      1011.899999             6.160173            16.935310  \n",
       "3060     93.132630       925.200020            10.063586            24.192429  \n",
       "\n",
       "[4739 rows x 15 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data_smoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='AQI', ylabel='Count'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribtion of AQI after SMOTER\n",
    "sns.histplot(model_data_smoter['AQI'], bins=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Without SMOTER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Evaluation:\n",
    "- RMSE\n",
    "- MSE\n",
    "- R-Squared"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark (Ordinary Least Squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the data\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Perform cross-validation\n",
    "ols_cv = cross_val_score(linear_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "ols_cv_r2 = cross_val_score(linear_model, X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance\n",
    "ols_mse = mean_squared_error(y_test, y_pred)\n",
    "ols_rmse = np.sqrt(ols_mse)\n",
    "ols_r2 = r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Cross Validate\n",
    "rf_cv = cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rf_cv_r2 = cross_val_score(rf, X, y, cv=5, scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "rf_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "rf_rmse = np.sqrt(rf_mse)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomisedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Prepare data\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Random number of trees between 50 and 200\n",
    "    'max_depth': randint(5, 20),  # Random depth between 5 and 20\n",
    "    'min_samples_split': randint(2, 10),  # Random min samples for split between 2 and 10\n",
    "    'min_samples_leaf': randint(1, 10),  # Random min samples at leaf between 1 and 10\n",
    "    'max_features': ['sqrt', 'log2', None]  # Replace 'auto' with 'sqrt', 'log2', or None\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, \n",
    "                                   n_iter=20, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Access cross val results\n",
    "rf_results = random_search.cv_results_\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "rf_mse_best = mean_squared_error(y_test, y_pred_best_rf)\n",
    "rf_rmse_best = np.sqrt(rf_mse_best)\n",
    "rf_r2_best = r2_score(y_test, y_pred_best_rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (SVR requires standardized input)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit the Support Vector Regression model\n",
    "svr = SVR(kernel='rbf')  # Using RBF kernel for non-linear relationships\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svr = svr.predict(X_test_scaled)\n",
    "\n",
    "# Cross Validate\n",
    "svr_cv = cross_val_score(svr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "svr_cv_r2 = cross_val_score(svr, X, y, cv=5, scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "svr_mse = mean_squared_error(y_test, y_pred_svr)\n",
    "svr_rmse = np.sqrt(svr_mse)\n",
    "svr_r2 = r2_score(y_test, y_pred_svr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomisedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 37.55401188473625, 'epsilon': 0.9607143064099162, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "# Prepare the data\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (SVR requires standardized input)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Support Vector Regressor (SVR)\n",
    "svr = SVR()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'C': uniform(0.1, 100),  # Regularization parameter between 0.1 and 100\n",
    "    'epsilon': uniform(0.01, 1),  # Epsilon value for margin\n",
    "    'gamma': ['scale', 'auto'],  # Gamma parameter for the RBF kernel\n",
    "    'kernel': ['rbf', 'linear']  # Kernel options\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV for tuning\n",
    "random_search_svr = RandomizedSearchCV(svr, param_distributions=param_dist, \n",
    "                                       n_iter=20, cv=5, scoring='neg_mean_squared_error', \n",
    "                                       random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Access cross validation results\n",
    "svr_results = random_search_svr.cv_results_\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_svr = random_search_svr.best_params_\n",
    "print(f\"Best parameters found: {best_params_svr}\")\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_svr = random_search_svr.best_estimator_\n",
    "y_pred_best_svr = best_svr.predict(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "svr_mse_best = mean_squared_error(y_test, y_pred_best_svr)\n",
    "svr_rmse_best = np.sqrt(svr_mse_best)\n",
    "svr_r2_best = r2_score(y_test, y_pred_best_svr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the data\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost Regressor with default or manually chosen parameters\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Perform cross-validation for MSE and R-squared\n",
    "xgb_cv_mse = cross_val_score(xgb_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "xgb_cv_r2 = cross_val_score(xgb_model, X, y, cv=5, scoring='r2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "xgb_mse = mean_squared_error(y_test, y_pred_xgb)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomisedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'colsample_bytree': 0.8035171238433423, 'learning_rate': 0.092799754606763, 'max_depth': 7, 'n_estimators': 64, 'reg_alpha': 0.01652669390630025, 'reg_lambda': 0.11563640674119394, 'subsample': 0.7117007403531848}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the data\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Number of trees (estimators)\n",
    "    'learning_rate': uniform(0.01, 0.3),  # Learning rate (eta)\n",
    "    'max_depth': randint(3, 10),  # Depth of trees\n",
    "    'subsample': uniform(0.5, 0.5),  # Subsampling of rows\n",
    "    'colsample_bytree': uniform(0.5, 0.5),  # Subsampling of columns\n",
    "    'reg_alpha': uniform(0, 0.1),  # L1 regularization (alpha)\n",
    "    'reg_lambda': uniform(0.1, 1.0),  # L2 regularization (lambda)\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV for tuning\n",
    "random_search_xgb = RandomizedSearchCV(xgb_model, param_distributions=param_dist, \n",
    "                                       n_iter=20, cv=5, scoring='neg_mean_squared_error', \n",
    "                                       random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Access cross validation results\n",
    "xgb_results = random_search_xgb.cv_results_\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "print(f\"Best parameters found: {best_params_xgb}\")\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "y_pred_best_xgb = best_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "xgb_mse_best = mean_squared_error(y_test, y_pred_best_xgb)\n",
    "xgb_rmse_best = np.sqrt(xgb_mse_best)\n",
    "xgb_r2_best = r2_score(y_test, y_pred_best_xgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Neural Network + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Initialize XGBoost and Neural Network as base learners\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=5000, random_state=42)\n",
    "\n",
    "# Create the stacking model using Linear Regression as the meta-model\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_model), ('nn', nn_model)],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the stacked model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_stacked = stacked_model.predict(X_test)\n",
    "\n",
    "hybrid_cv = cross_val_score(stacked_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "hybrid_cv_r2 = cross_val_score(stacked_model, X, y, cv=5, scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "stacked_mse = mean_squared_error(y_test, y_pred_stacked)\n",
    "stacked_rmse = np.sqrt(stacked_mse)\n",
    "stacked_r2 = r2_score(y_test, y_pred_stacked)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'nn__activation': 'relu', 'nn__alpha': 0.006475574713552132, 'nn__hidden_layer_sizes': (100, 100), 'nn__solver': 'adam', 'xgb__colsample_bytree': 0.7806217129238506, 'xgb__learning_rate': 0.12487806242613694, 'xgb__max_depth': 9, 'xgb__n_estimators': 180, 'xgb__subsample': 0.8803925243084487}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Prepare data\n",
    "X = model_data.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize base models\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "nn_model = MLPRegressor(max_iter=5000, random_state=42, verbose=False)\n",
    "\n",
    "# Define the stacking model\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_model), ('nn', nn_model)],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# Define hyperparameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': randint(50, 200),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.3),\n",
    "    'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__subsample': uniform(0.5, 0.5),  # Generates values strictly between 0.5 and 1.0\n",
    "    'xgb__colsample_bytree': uniform(0.5, 0.5),  # Same, strictly between 0.5 and 1.0\n",
    "    \n",
    "    'nn__hidden_layer_sizes': [(50,), (100,), (100, 100)],\n",
    "    'nn__activation': ['relu'],\n",
    "    'nn__alpha': uniform(0.0001, 0.01),  # Reasonable regularization range\n",
    "    'nn__solver': ['adam']\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=stacked_model, \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_iter=20, \n",
    "                                   cv=5, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   random_state=42, \n",
    "                                   n_jobs=1,  # No parallel jobs\n",
    "                                   error_score='raise')  # Raise errors\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Access cross-validation results\n",
    "stacked_restults = random_search.cv_results_\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_stacked_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Make predictions and evaluate the tuned stacked model\n",
    "y_pred_best_stacked = best_stacked_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "stacked_mse_best = mean_squared_error(y_test, y_pred_best_stacked)\n",
    "stacked_rmse_best = np.sqrt(stacked_mse_best)\n",
    "stacked_r2_best = r2_score(y_test, y_pred_best_stacked)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 23.33233531638366\n",
      "P-value: 8.293453264143274e-11\n",
      "There is a statistically significant difference between the models.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "rf_results_mse = rf_results['mean_test_score']\n",
    "svr_results_mse = svr_results['mean_test_score']\n",
    "xgb_results_mse = xgb_results['mean_test_score']\n",
    "stacked_restults_mse = stacked_restults['mean_test_score']\n",
    "\n",
    "# Perform ANOVA test\n",
    "f_statistic, p_value = f_oneway(rf_results_mse, svr_results_mse, xgb_results_mse, stacked_restults_mse)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of ANOVA test result\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the models.\")\n",
    "else:\n",
    "    print(\"No statistically significant difference between the models.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05         \n",
      "=====================================================================\n",
      "    group1        group2    meandiff p-adj    lower    upper   reject\n",
      "---------------------------------------------------------------------\n",
      " Hybrid Model Random Forest -165.775    0.0 -240.2998 -91.2501   True\n",
      " Hybrid Model           SVG -138.661    0.0 -213.1858 -64.1361   True\n",
      " Hybrid Model       XGBoost  26.8766 0.7794  -47.6482 101.4014  False\n",
      "Random Forest           SVG   27.114 0.7748  -47.4108 101.6389  False\n",
      "Random Forest       XGBoost 192.6516    0.0  118.1267 267.1764   True\n",
      "          SVG       XGBoost 165.5375    0.0   91.0127 240.0624   True\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Example MSE data for three models\n",
    "# Replace with your cross-validated MSE data\n",
    "mse_data = np.concatenate([rf_results_mse, svr_results_mse, xgb_results_mse, stacked_restults_mse])\n",
    "\n",
    "# Corresponding labels for the models\n",
    "model_labels = (['Random Forest'] * len(rf_results_mse)) + (['SVG'] * len(svr_results_mse)) + (['XGBoost'] * len(xgb_results_mse) + (['Hybrid Model'] * len(stacked_restults_mse)))\n",
    "\n",
    "# Create a DataFrame to hold the MSE values and corresponding model labels\n",
    "df = pd.DataFrame({'MSE': mse_data, 'Model': model_labels})\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=df['MSE'], groups=df['Model'], alpha=0.05)\n",
    "\n",
    "# Display the test results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RÂ²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>626.176561</td>\n",
       "      <td>25.023520</td>\n",
       "      <td>0.833876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>594.982597</td>\n",
       "      <td>24.392265</td>\n",
       "      <td>0.842152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR</td>\n",
       "      <td>632.752777</td>\n",
       "      <td>25.154578</td>\n",
       "      <td>0.832131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>700.701540</td>\n",
       "      <td>26.470768</td>\n",
       "      <td>0.814104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB + NN</td>\n",
       "      <td>678.361974</td>\n",
       "      <td>26.045383</td>\n",
       "      <td>0.820031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model         MSE       RMSE        RÂ²\n",
       "0            OLS  626.176561  25.023520  0.833876\n",
       "1  Random Forest  594.982597  24.392265  0.842152\n",
       "2            SVR  632.752777  25.154578  0.832131\n",
       "3            XGB  700.701540  26.470768  0.814104\n",
       "4       XGB + NN  678.361974  26.045383  0.820031"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for Metric Comparison without SMOTER\n",
    "\n",
    "models = ['OLS', 'Random Forest', 'SVR', 'XGB', 'XGB + NN']\n",
    "mse = [ols_mse, rf_mse_best, svr_mse_best, xgb_mse_best, stacked_mse_best]\n",
    "rmse = [ols_rmse, rf_rmse_best, svr_rmse_best, xgb_rmse_best, stacked_rmse_best]\n",
    "r2 = [ols_r2, rf_r2_best, svr_r2_best, xgb_r2_best, stacked_r2_best]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'RÂ²': r2\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation with SMOTER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark (Ordinary Least Squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the data\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Perform cross-validation\n",
    "ols_cv_smoter = cross_val_score(linear_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "ols_cv_r2_smoter = cross_val_score(linear_model, X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model performance\n",
    "ols_mse_smoter = mean_squared_error(y_test, y_pred)\n",
    "ols_rmse_smoter = np.sqrt(ols_mse)\n",
    "ols_r2_smoter = r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Cross Validate\n",
    "rf_cv = cross_val_score(rf, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rf_cv_r2 = cross_val_score(rf, X, y, cv=5, scoring='r2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "rf_mse_smoter = mean_squared_error(y_test, y_pred_rf)\n",
    "rf_rmse_smoter = np.sqrt(rf_mse_smoter)\n",
    "rf_r2_smoter = r2_score(y_test, y_pred_rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomisedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'max_depth': 17, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Prepare data\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Random number of trees between 50 and 200\n",
    "    'max_depth': randint(5, 20),  # Random depth between 5 and 20\n",
    "    'min_samples_split': randint(2, 10),  # Random min samples for split between 2 and 10\n",
    "    'min_samples_leaf': randint(1, 10),  # Random min samples at leaf between 1 and 10\n",
    "    'max_features': ['sqrt', 'log2', None]  # Replace 'auto' with 'sqrt', 'log2', or None\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, \n",
    "                                   n_iter=20, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Access cross val results\n",
    "rf_results_smoter = random_search.cv_results_\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_rf = random_search.best_estimator_\n",
    "y_pred_best_rf = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "rf_mse_best_smoter = mean_squared_error(y_test, y_pred_best_rf)\n",
    "rf_rmse_best_smoter = np.sqrt(rf_mse_best_smoter)\n",
    "rf_r2_best_smoter = r2_score(y_test, y_pred_best_rf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (SVR requires standardized input)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and fit the Support Vector Regression model\n",
    "svr = SVR(kernel='rbf')  # Using RBF kernel for non-linear relationships\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_svr = svr.predict(X_test_scaled)\n",
    "\n",
    "# Cross Validate\n",
    "svr_cv = cross_val_score(svr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "svr_cv_r2 = cross_val_score(svr, X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "svr_mse_smoter = mean_squared_error(y_test, y_pred_svr)\n",
    "svr_rmse_smoter = np.sqrt(svr_mse_smoter)\n",
    "svr_r2_smoter = r2_score(y_test, y_pred_svr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomisedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'C': 59.96584841970366, 'epsilon': 0.16601864044243653, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "# Prepare the data\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (SVR requires standardized input)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Support Vector Regressor (SVR)\n",
    "svr = SVR()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'C': uniform(0.1, 100),  # Regularization parameter between 0.1 and 100\n",
    "    'epsilon': uniform(0.01, 1),  # Epsilon value for margin\n",
    "    'gamma': ['scale', 'auto'],  # Gamma parameter for the RBF kernel\n",
    "    'kernel': ['rbf', 'linear']  # Kernel options\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV for tuning\n",
    "random_search_svr = RandomizedSearchCV(svr, param_distributions=param_dist, \n",
    "                                       n_iter=20, cv=5, scoring='neg_mean_squared_error', \n",
    "                                       random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Access cross validation results\n",
    "svr_results_smoter = random_search_svr.cv_results_\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_svr = random_search_svr.best_params_\n",
    "print(f\"Best parameters found: {best_params_svr}\")\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_svr = random_search_svr.best_estimator_\n",
    "y_pred_best_svr = best_svr.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "svr_mse_best_smoter = mean_squared_error(y_test, y_pred_best_svr)\n",
    "svr_rmse_best_smoter = np.sqrt(svr_mse_best_smoter)\n",
    "svr_r2_best_smoter = r2_score(y_test, y_pred_best_svr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the data\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost Regressor with default or manually chosen parameters\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Perform cross-validation for MSE and R-squared\n",
    "xgb_cv_mse = cross_val_score(xgb_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "xgb_cv_r2 = cross_val_score(xgb_model, X, y, cv=5, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "xgb_mse_smoter = mean_squared_error(y_test, y_pred_xgb)\n",
    "xgb_rmse_smoter = np.sqrt(xgb_mse_smoter)\n",
    "xgb_r2_smoter = r2_score(y_test, y_pred_xgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomisedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'colsample_bytree': 0.6974407590877849, 'learning_rate': 0.09804645241541143, 'max_depth': 9, 'n_estimators': 188, 'reg_alpha': 0.019884240408880517, 'reg_lambda': 0.81134195274865, 'subsample': 0.8950877702656028}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Prepare the data\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost Regressor\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(50, 200),  # Number of trees (estimators)\n",
    "    'learning_rate': uniform(0.01, 0.3),  # Learning rate (eta)\n",
    "    'max_depth': randint(3, 10),  # Depth of trees\n",
    "    'subsample': uniform(0.5, 0.5),  # Subsampling of rows\n",
    "    'colsample_bytree': uniform(0.5, 0.5),  # Subsampling of columns\n",
    "    'reg_alpha': uniform(0, 0.1),  # L1 regularization (alpha)\n",
    "    'reg_lambda': uniform(0.1, 1.0),  # L2 regularization (lambda)\n",
    "}\n",
    "\n",
    "# Use RandomizedSearchCV for tuning\n",
    "random_search_xgb = RandomizedSearchCV(xgb_model, param_distributions=param_dist, \n",
    "                                       n_iter=20, cv=5, scoring='neg_mean_squared_error', \n",
    "                                       random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Access cross validation results\n",
    "xgb_results_smoter = random_search_xgb.cv_results_\n",
    "\n",
    "# Get the best parameters\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "print(f\"Best parameters found: {best_params_xgb}\")\n",
    "\n",
    "# Use the best model to make predictions\n",
    "best_xgb = random_search_xgb.best_estimator_\n",
    "y_pred_best_xgb = best_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "xgb_mse_best_smoter = mean_squared_error(y_test, y_pred_best_xgb)\n",
    "xgb_rmse_best_smoter = np.sqrt(xgb_mse_best_smoter)\n",
    "xgb_r2_best_smoter = r2_score(y_test, y_pred_best_xgb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked Neural Network + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Initialize XGBoost and Neural Network as base learners\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=5000, random_state=42)\n",
    "\n",
    "# Create the stacking model using Linear Regression as the meta-model\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_model), ('nn', nn_model)],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the stacked model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_stacked = stacked_model.predict(X_test)\n",
    "\n",
    "hybrid_cv = cross_val_score(stacked_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "hybrid_cv_r2 = cross_val_score(stacked_model, X, y, cv=5, scoring='r2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "stacked_mse_smoter = mean_squared_error(y_test, y_pred_stacked)\n",
    "stacked_rmse_smoter = np.sqrt(stacked_mse_smoter)\n",
    "stacked_r2_smoter = r2_score(y_test, y_pred_stacked)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning using RandomisedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'nn__activation': 'relu', 'nn__alpha': 0.0010997491581800289, 'nn__hidden_layer_sizes': (100, 100), 'nn__solver': 'adam', 'xgb__colsample_bytree': 0.9330880728874675, 'xgb__learning_rate': 0.19033450352296263, 'xgb__max_depth': 5, 'xgb__n_estimators': 199, 'xgb__subsample': 0.5282057895135501}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Prepare data\n",
    "X = model_data_smoter.drop(['City', 'Date', 'AQI'], axis=1)\n",
    "y = model_data_smoter['AQI']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize base models\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "nn_model = MLPRegressor(max_iter=5000, random_state=42, verbose=False)\n",
    "\n",
    "# Define the stacking model\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=[('xgb', xgb_model), ('nn', nn_model)],\n",
    "    final_estimator=LinearRegression()\n",
    ")\n",
    "\n",
    "# Define hyperparameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'xgb__n_estimators': randint(50, 200),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.3),\n",
    "    'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__subsample': uniform(0.5, 0.5),  # Generates values strictly between 0.5 and 1.0\n",
    "    'xgb__colsample_bytree': uniform(0.5, 0.5),  # Same, strictly between 0.5 and 1.0\n",
    "    \n",
    "    'nn__hidden_layer_sizes': [(50,), (100,), (100, 100)],\n",
    "    'nn__activation': ['relu'],\n",
    "    'nn__alpha': uniform(0.0001, 0.01),  # Reasonable regularization range\n",
    "    'nn__solver': ['adam']\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=stacked_model, \n",
    "                                   param_distributions=param_grid, \n",
    "                                   n_iter=20, \n",
    "                                   cv=5, \n",
    "                                   scoring='neg_mean_squared_error',\n",
    "                                   random_state=42, \n",
    "                                   n_jobs=1,  # No parallel jobs\n",
    "                                   error_score='raise')  # Raise errors\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Access cross-validation results\n",
    "stacked_restults_smoter = random_search.cv_results_\n",
    "\n",
    "# Get the best parameters and best model\n",
    "best_stacked_model = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Make predictions and evaluate the tuned stacked model\n",
    "y_pred_best_stacked = best_stacked_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "stacked_mse_best_smoter = mean_squared_error(y_test, y_pred_best_stacked)\n",
    "stacked_rmse_best_smoter = np.sqrt(stacked_mse_best_smoter)\n",
    "stacked_r2_best_smoter = r2_score(y_test, y_pred_best_stacked)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 47.72353408878284\n",
      "P-value: 1.8977839734853493e-17\n",
      "There is a statistically significant difference between the models.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "rf_results_mse_smoter = rf_results_smoter['mean_test_score']\n",
    "svr_results_mse_smoter = svr_results_smoter['mean_test_score']\n",
    "xgb_results_mse_smoter = xgb_results_smoter['mean_test_score']\n",
    "stacked_restults_mse_smoter = stacked_restults_smoter['mean_test_score']\n",
    "\n",
    "# Perform ANOVA test\n",
    "f_statistic, p_value = f_oneway(rf_results_mse_smoter, svr_results_mse_smoter, xgb_results_mse_smoter, stacked_restults_mse_smoter)\n",
    "\n",
    "# Output the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of ANOVA test result\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a statistically significant difference between the models.\")\n",
    "else:\n",
    "    print(\"No statistically significant difference between the models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Multiple Comparison of Means - Tukey HSD, FWER=0.05          \n",
      "======================================================================\n",
      "    group1        group2     meandiff p-adj    lower    upper   reject\n",
      "----------------------------------------------------------------------\n",
      " Hybrid Model Random Forest -187.1316 0.0002 -297.3441 -76.9191   True\n",
      " Hybrid Model           SVG -327.0625    0.0  -437.275  -216.85   True\n",
      " Hybrid Model       XGBoost  138.7885 0.0077    28.576  249.001   True\n",
      "Random Forest           SVG -139.9309 0.0071 -250.1434 -29.7184   True\n",
      "Random Forest       XGBoost  325.9201    0.0  215.7076 436.1325   True\n",
      "          SVG       XGBoost   465.851    0.0  355.6385 576.0635   True\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Example MSE data for three models\n",
    "# Replace with your cross-validated MSE data\n",
    "mse_data = np.concatenate([rf_results_mse_smoter, svr_results_mse_smoter, xgb_results_mse_smoter, stacked_restults_mse_smoter])\n",
    "\n",
    "# Corresponding labels for the models\n",
    "model_labels = (['Random Forest'] * len(rf_results_mse_smoter)) + (['SVG'] * len(svr_results_mse_smoter)) + (['XGBoost'] * len(xgb_results_mse_smoter) + (['Hybrid Model'] * len(stacked_restults_mse_smoter)))\n",
    "\n",
    "# Create a DataFrame to hold the MSE values and corresponding model labels\n",
    "df = pd.DataFrame({'MSE': mse_data, 'Model': model_labels})\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=df['MSE'], groups=df['Model'], alpha=0.05)\n",
    "\n",
    "# Display the test results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RÂ²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>1753.697376</td>\n",
       "      <td>25.023520</td>\n",
       "      <td>0.771458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>611.067097</td>\n",
       "      <td>24.719771</td>\n",
       "      <td>0.920366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVR</td>\n",
       "      <td>662.201771</td>\n",
       "      <td>25.733281</td>\n",
       "      <td>0.913702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>642.126416</td>\n",
       "      <td>25.340213</td>\n",
       "      <td>0.916318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB + NN</td>\n",
       "      <td>655.096730</td>\n",
       "      <td>25.594857</td>\n",
       "      <td>0.919216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model          MSE       RMSE        RÂ²\n",
       "0            OLS  1753.697376  25.023520  0.771458\n",
       "1  Random Forest   611.067097  24.719771  0.920366\n",
       "2            SVR   662.201771  25.733281  0.913702\n",
       "3            XGB   642.126416  25.340213  0.916318\n",
       "4       XGB + NN   655.096730  25.594857  0.919216"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for Metric Comparison without SMOTER\n",
    "\n",
    "models = ['OLS', 'Random Forest', 'SVR', 'XGB', 'XGB + NN']\n",
    "mse = [ols_mse_smoter, rf_mse_best_smoter, svr_mse_best_smoter, xgb_mse_best_smoter, stacked_mse_best_smoter]\n",
    "rmse = [ols_rmse_smoter, rf_rmse_best_smoter, svr_rmse_best_smoter, xgb_rmse_best_smoter, stacked_rmse_best_smoter]\n",
    "r2 = [ols_r2_smoter, rf_r2_best_smoter, svr_r2_best_smoter, xgb_r2_best_smoter, stacked_r2_best_smoter]\n",
    "\n",
    "# Create the DataFrame\n",
    "df_results_smoter = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse,\n",
    "    'RÂ²': r2\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "df_results_smoter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE vs Without SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
